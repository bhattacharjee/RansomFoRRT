{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattacharjee/msc-ai-project/blob/main/iteration_2.1/COLABTEST_iteration_2_1_LR_compare_base32_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac0f82a",
      "metadata": {
        "id": "fac0f82a"
      },
      "source": [
        "Few key observations\n",
        "- If both and non-encrypted files are base-32 encoded, accuracy drops really low.\n",
        "   * Even in this case, fourier analysis (specifically autocorrelation and mean) provide good discrminators\n",
        "   * Renyi's entropy at alpha=infinity gives good discrimination\n",
        "   * Overall we see around 13% improvement in F1-score\n",
        "- Specifically for webpfiles\n",
        "   * We see that higher moments of around 14 gives a good discrimination\n",
        "   * Fourier analysis still gives benefits here\n",
        "- For webpfiles where both unencrypted and encrypted content are base32 encrypted\n",
        "   * Fourier analysis is still beneficial\n",
        "- For Non-webp files where plaintext is not base-32 encrypted\n",
        "   * Accuracy is decent with just the base parameters, but with fourier analysis, we can close to perfect detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d893d930",
      "metadata": {
        "id": "d893d930"
      },
      "source": [
        "# Contents\n",
        "- ## [Implementation](#mplementation)\n",
        " - ### [List of Files](#list-of-files)\n",
        " - ### [Utility to call gc](#gc)\n",
        " - ### [Selection of Columns](#select-columns)\n",
        " - ### [Function to compare the three selections of columns for a given dataset](#compare-fn)\n",
        " - ### [Load the datasets](#load-dataset)\n",
        " - ### [Select the datasets](#dataset-selection)\n",
        " - ### [Run all combinations of data](#dataset-selection)\n",
        "- ## [Results](#results)\n",
        " - ### [Print the raw results](#raw-results)\n",
        " - ### [Sort by the improvement when using Fourier transforms over baseline](#sorted-fourier)\n",
        " - ### [Measure improvement when only webp files are used](#webp-only)\n",
        " - ### [Measure improvement when webp files are not present](#no-webp)\n",
        " - ### [Measure improvement for balanced datasets](#balanced-dataset)\n",
        " - ### [Measure the improvement when all files are used](#full-dataset)\n",
        " - ### [Focus on items where the base metrics performed well](#focus-greater-90)\n",
        " - ### [Correlation of data set and performance](\"corr-heatmap\")\n",
        " - ### [Average out all the metrics](#mean-fscores)\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15575342",
      "metadata": {
        "id": "15575342"
      },
      "source": [
        "## Implementation <a class=\"anchor\" id=\"implementation\">\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4accc0da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4accc0da",
        "outputId": "74b0b7fb-0bde-4178-b733-d46f34c578c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/root/workdir\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"tqdm>=4.36.1\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "import gc\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!mkdir /root/workdir\n",
        "!cp /content/gdrive/MyDrive/MSCPROJDATA/*.gz /root/workdir\n",
        "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
        "os.chdir(\"/root/workdir\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8L2UBRiM5Xu",
        "outputId": "931e3944-20ab-4fc5-dbd4-47ca8f995754"
      },
      "id": "p8L2UBRiM5Xu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              4\n",
            "On-line CPU(s) list: 0-3\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  2\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0-3\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "814fac30",
      "metadata": {
        "id": "814fac30"
      },
      "source": [
        "### List of files <a class=\"anchor\" id=\"list-of-files\">\n",
        "\n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21f06ca7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21f06ca7",
        "outputId": "94ee2b59-d589-4c13-e071-db8271d0c2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "expanded.plaintext.base32.parquet.gz\t   expanded.pyencrypted_v2.parquet.gz\n",
            "expanded.pyencrypted_v1.b32.parquet.gz\t   plaintext.base32.combined.parquet.gz\n",
            "expanded.pyencrypted_v1.parquet.gz\t   plaintext.combined.parquet.gz\n",
            "expanded.pyencrypted_v2.base32.parquet.gz  plaintext.expanded.parquet.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767e59e6",
      "metadata": {
        "id": "767e59e6"
      },
      "source": [
        "### Utility to call GC <a class=\"anchor\" id=\"gc\">\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17a1dd0",
      "metadata": {
        "id": "c17a1dd0"
      },
      "outputs": [],
      "source": [
        "def call_gc():\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            gc.collect(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c10d08",
      "metadata": {
        "id": "82c10d08"
      },
      "source": [
        "### Selection of columns <a class=\"anchor\" id=\"select-columns\">\n",
        "    \n",
        "This function is used to select the columns.\n",
        "There are three different configurations:\n",
        "    \n",
        "    1. Baseline - statistics like autocorrelation, shannon entropy, chi-square etc. are used\n",
        "    \n",
        "    2. Advanced - More statistics like moments, Tsallis and Renyi entropy, higher moments etc.\n",
        "    \n",
        "    3. Fourier - Some statistics of the Fourier Power Spectrum distribution\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffaf53cc",
      "metadata": {
        "id": "ffaf53cc"
      },
      "outputs": [],
      "source": [
        "def get_columns(thisdf):\n",
        "    baseline_columns = [c for c in thisdf.columns if c.startswith('baseline') and \"head\" not in c and \"tail\" not in c]\n",
        "    baseline_columns = [c for c in baseline_columns if \"filesize\" not in c]\n",
        "    baseline_columns = [c for c in baseline_columns if \"begin\" not in c and \"end\" not in c]\n",
        "\n",
        "    advanced_columns = [c for c in thisdf.columns if \"advanced\" in c]\n",
        "    advanced_columns = [c for c in advanced_columns if \"begin\" not in c and \"end\" not in c]\n",
        "    advanced_columns = [c for c in advanced_columns if \"head\" not in c and \"tail\" not in c]\n",
        "    advanced_columns = [c for c in advanced_columns if \"start\" not in c]\n",
        "    advanced_columns_only = list(set(advanced_columns))\n",
        "    advanced_columns = list(set(advanced_columns + baseline_columns))\n",
        "\n",
        "    fourier_columns = [c for c in thisdf.columns if \"fourier\" in c and \"value\" not in c]\n",
        "    fourier_columns = [c for c in fourier_columns if \"1byte\" in c]\n",
        "    fourier_columns = [c for c in fourier_columns if \"begin\" not in c and \"end\" not in c]\n",
        "    fourier_columns = [c for c in fourier_columns if \"head\" not in c and \"tail\" not in c]\n",
        "    fourier_columns = [c for c in fourier_columns if \"start\" not in c]\n",
        "    fourier_columns_only = list(set(fourier_columns))\n",
        "    fourier_columns = list(set(advanced_columns + fourier_columns))\n",
        "    \n",
        "    return {\\\n",
        "        \"baseline\": baseline_columns,\\\n",
        "        \"advanced\": advanced_columns,\\\n",
        "        \"advanced-only\": advanced_columns_only,\\\n",
        "        \"fourier\": fourier_columns,\\\n",
        "        \"fourier-only\": fourier_columns_only,\\\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "256b9ded",
      "metadata": {
        "id": "256b9ded"
      },
      "source": [
        "### Function to compare the three selections of columns for a given dataset <a class=\"anchor\" id=\"compare-fn\">\n",
        "    \n",
        "For the three different sets of measurements described above, compare all the three sets for their f1 score\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df5b08e7",
      "metadata": {
        "id": "df5b08e7"
      },
      "outputs": [],
      "source": [
        "def compare_feature_selections(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "    columns_dict = get_columns(X)\n",
        "    ret = dict()\n",
        "    for name, collist in columns_dict.items():\n",
        "        XX_train, XX_test = X_train[collist], X_test[collist]\n",
        "        #rfc = RandomForestClassifier(n_jobs=10, random_state=42)\n",
        "        lr = LogisticRegression(n_jobs=10, random_state=42, max_iter=300)\n",
        "        estimators = [('std,', MinMaxScaler()), ('LogisticRegression', lr)]\n",
        "        pipeline = Pipeline(estimators)\n",
        "        pipeline.fit(XX_train, y_train)\n",
        "        y_pred = pipeline.predict(XX_test)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        ret[f\"{name}-f1_score\"] = f1\n",
        "    return ret\n",
        "\n",
        "def compare_feature_selections_wrapper(data):\n",
        "    X = data[[c for c in data.columns if \"is_encrypted\" != c]]\n",
        "    y = data[\"is_encrypted\"]\n",
        "    return compare_feature_selections(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1846248",
      "metadata": {
        "id": "a1846248"
      },
      "source": [
        "### Load the datasets <a class=\"anchor\" id=\"load-dataset\">\n",
        "\n",
        "We don't want to load the datasets again and again, so we load them once.\n",
        "The LRU cache ensures that the next time this is called, we don't load the datasets again.\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff1b84c",
      "metadata": {
        "id": "4ff1b84c"
      },
      "outputs": [],
      "source": [
        "@lru_cache\n",
        "def load_datasets_once():\n",
        "    \"\"\"Load all datasets only once\n",
        "    \n",
        "    We want to load the datasets only once. Once loaded\n",
        "    serve from cache\n",
        "    \"\"\"\n",
        "    datasets = dict()\n",
        "    for file in glob.glob(\"*.parquet.gz\"):\n",
        "        df = pd.read_parquet(file)\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "        df[\"is_encrypted\"] = 1 if \"encr\" in file.lower() else 0\n",
        "        datasets[file] = df\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da5cb0c",
      "metadata": {
        "id": "5da5cb0c"
      },
      "source": [
        "### Select the datasets <a class=\"anchor\" id=\"dataset-selection\">\n",
        "\n",
        "Select the dataset, combine it, shuffle it and return\n",
        "    \n",
        "We used several schemes:\n",
        "* Plaintext\n",
        "  - The base plaintext dataset of around 50k files\n",
        "  - Expanded dataset, where all files that were less than 1500 bytes were expanded by repeating the file\n",
        "  - Base32 encoding of\n",
        "   - original plaintext\n",
        "   - expanded plaintext\n",
        "* Encryption : We used two schemes for encruption\n",
        "  - v1 : AES 256 encryption of the full file, again two varieties were used\n",
        "    - Plain encryption\n",
        "    - Encryption followed by base32 encoding\n",
        "  - v2 : AES encryption of the file, the first and the last 128 bytes are not encrypted. Of the remaining file, every alternate 16 bytes are encrypted.\n",
        "    - Plain encryption\n",
        "    - encryption followed by base32 encoding\n",
        "    \n",
        "We select combinations of the above datasets\n",
        "    \n",
        "Furthermore, we add further combinations by including and excluding webp files, and including and excluding non-webp files.\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45391110",
      "metadata": {
        "id": "45391110"
      },
      "outputs": [],
      "source": [
        "def get_dataset(\\\n",
        "               exclude_plaintext_nonbase32=False,\n",
        "               exclude_plaintext_base32=False,\n",
        "               exclude_encrypted_v1=False,\n",
        "               exclude_encrypted_v2=False,\n",
        "               exclude_encrypted_base32=False,\n",
        "               exclude_encrypted_nonbase32=False,\n",
        "               exclude_webp=False,\n",
        "               exclude_nonwebp=False):\n",
        "    description = {k:v for k,v in locals().items() if \"exclude\" in k}\n",
        "    files = glob.glob(\"*.parquet.gz\")\n",
        "    \n",
        "    \n",
        "    if exclude_plaintext_nonbase32:\n",
        "        files = [f for f in files if \\\n",
        "                     \"plaintext\" not in f \\\n",
        "                     or \"_base32\" in f \\\n",
        "                     or \"_b32\" in f]\n",
        "    if exclude_plaintext_base32:\n",
        "        files = [f for f in files if\\\n",
        "                    \"plaintext\" not in f or \\\n",
        "                    (\"base32\" not in f and \"b32\" not in f)]\n",
        "    if exclude_encrypted_v1:\n",
        "        files = [f for f in files if\\\n",
        "                    \"_v1\" not in f or \"encr\" not in f]\n",
        "    if exclude_encrypted_v2:\n",
        "        files = [f for f in files if \\\n",
        "                    \"_v2\" not in f or \"encr\" not in f]\n",
        "    if exclude_encrypted_base32:\n",
        "        files = [ f for f in files if\\\n",
        "                    \"encr\" not in f or\\\n",
        "                    (\"base32\" not in f and \"b32\" not in f)]\n",
        "    if exclude_encrypted_nonbase32:\n",
        "        files = [f for f in files if \\\n",
        "                    \"encr\" not in f or \\\n",
        "                    \"base32\" in f or \"b32\" in f]\n",
        "        \n",
        "        \n",
        "    encrypted_count = len([f for f in files if \"encr\" in f])\n",
        "    non_encrypted_count = len([f for f in files if \"encr\" not in f])\n",
        "    \n",
        "    if 0 == encrypted_count or 0 == non_encrypted_count or 0 == len(files):\n",
        "        return description, None, -1, -1\n",
        "    \n",
        "    all_dfs = list()\n",
        "    all_loaded_datasets = load_datasets_once()\n",
        "    for filename in files:\n",
        "        all_dfs.append(all_loaded_datasets[filename])\n",
        "    \n",
        "    combined_df = pd.concat(all_dfs)\n",
        "    \n",
        "    if exclude_webp:\n",
        "        combined_df = combined_df[combined_df[\"extended.extension\"] != \".webp\"]\n",
        "    if exclude_nonwebp:\n",
        "        combined_df = combined_df[combined_df[\"extended.extension\"] == \".webp\"]\n",
        "        \n",
        "    if len(combined_df) == 0:\n",
        "        return description, None, -1, -1\n",
        "    \n",
        "        \n",
        "    encrypt_count = len(combined_df[combined_df[\"is_encrypted\"] == 1])\n",
        "    nonencrypted_count = len(combined_df[combined_df[\"is_encrypted\"] == 0])\n",
        "\n",
        "    \n",
        "    if 0 == len(combined_df) or 0 == encrypt_count or 0 == nonencrypted_count:\n",
        "        return description, None, -1, -1\n",
        "    \n",
        "    return description, combined_df, encrypt_count, nonencrypted_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7cd75b7",
      "metadata": {
        "id": "f7cd75b7"
      },
      "source": [
        "### Run all combinations of data <a class=\"anchor\" id=\"dataset-selection\">\n",
        "\n",
        "For all combinations of the datasets, compare the three classes (basic, advanced, and Fourier)\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5869ad",
      "metadata": {
        "id": "6f5869ad",
        "outputId": "01060fdc-4470-4fee-f3ac-81f2404fffab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|██████████████████████████████▎                     | 149/256 [01:52<01:20,  1.33it/s]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 59%|██████████████████████████████▍                     | 150/256 [03:41<03:08,  1.78s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 59%|██████████████████████████████▋                     | 151/256 [04:32<04:16,  2.44s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 61%|███████████████████████████████▉                    | 157/256 [11:29<23:08, 14.03s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 62%|████████████████████████████████                    | 158/256 [14:26<51:56, 31.80s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|███████████████████████████████                   | 159/256 [15:46<1:01:49, 38.24s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 65%|█████████████████████████████████▋                  | 166/256 [22:09<55:16, 36.85s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 68%|█████████████████████████████████▉                | 174/256 [29:01<1:17:45, 56.89s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 71%|████████████████████████████████████▊               | 181/256 [34:27<39:14, 31.39s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 71%|███████████████████████████████████▌              | 182/256 [37:22<1:11:12, 57.73s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 71%|███████████████████████████████████▋              | 183/256 [38:34<1:13:46, 60.64s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 74%|████████████████████████████████████▉             | 189/256 [48:27<1:16:56, 68.91s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 74%|████████████████████████████████████▎            | 190/256 [53:28<2:29:37, 136.02s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 75%|████████████████████████████████████▌            | 191/256 [56:26<2:40:45, 148.39s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 83%|█████████████████████████████████████████▌        | 213/256 [1:05:28<14:15, 19.90s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 84%|█████████████████████████████████████████▊        | 214/256 [1:09:33<23:21, 33.37s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 84%|█████████████████████████████████████████▉        | 215/256 [1:11:00<25:43, 37.64s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 85%|██████████████████████████████████████████▍       | 217/256 [1:18:19<44:43, 68.81s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 86%|████████████████████████████████████████▌      | 221/256 [1:28:09<1:02:22, 106.92s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 87%|████████████████████████████████████████▊      | 222/256 [1:33:12<1:27:36, 154.61s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 87%|████████████████████████████████████████▉      | 223/256 [1:36:10<1:28:19, 160.58s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 90%|████████████████████████████████████████████▉     | 230/256 [1:46:58<36:07, 83.36s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 93%|█████████████████████████████████████████████▋   | 239/256 [2:06:08<37:02, 130.73s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 96%|███████████████████████████████████████████████▊  | 245/256 [2:13:03<10:24, 56.77s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 96%|███████████████████████████████████████████████▎ | 247/256 [2:20:42<16:57, 113.11s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 97%|███████████████████████████████████████████████▋ | 249/256 [2:29:46<18:45, 160.81s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 99%|████████████████████████████████████████████████▍| 253/256 [2:43:47<08:56, 178.81s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            " 99%|████████████████████████████████████████████████▌| 254/256 [2:50:32<08:08, 244.22s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "100%|████████████████████████████████████████████████▊| 255/256 [2:54:46<04:07, 247.19s/it]/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/Users/phantom/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "100%|██████████████████████████████████████████████████| 256/256 [3:06:46<00:00, 43.78s/it]\n"
          ]
        }
      ],
      "source": [
        "all_results = []\n",
        "list_of_arguments = []\n",
        "count = 2\n",
        "for a in [True, False]:\n",
        "    for b in [True, False]:\n",
        "        for c in [True, False]:\n",
        "            for k in [True, False]:\n",
        "                for e in [True, False]:\n",
        "                    for f in [True, False]:\n",
        "                        for g in [True, False]:\n",
        "                            for h in [True, False]:\n",
        "                                arguments = (a, b, c, k, e, f, g, h,)\n",
        "                                list_of_arguments.append(arguments)\n",
        "                                \n",
        "for a, b, c, k, e, f, g, h in tqdm.tqdm(list_of_arguments):\n",
        "    desc, df, ec, nec = get_dataset(a, b, c, k, e, f, g, h)\n",
        "    if df is not None:\n",
        "        result = compare_feature_selections_wrapper(df)\n",
        "        call_gc()\n",
        "        result = {**desc, **result}\n",
        "        result[\"n_encrypted\"] = ec\n",
        "        result[\"n_non_encrypted\"] = nec\n",
        "        result[\"ratio_encrypt_nonencrypt\"] = float(ec) / nec\n",
        "        all_results.append(result)\n",
        "\n",
        "\n",
        "df_dict = {k:[] for k in all_results[0]}\n",
        "for result in all_results:\n",
        "    for k, v in result.items():\n",
        "        df_dict[k].append(v)\n",
        "\n",
        "df = pd.DataFrame(df_dict)\n",
        "df[\"best_f1_score\"] = df[[c for c in df.columns if \"f1_score\" in c]].max(axis=1)\n",
        "\n",
        "df[\"improvement_in_advanced\"] = df[\"advanced-f1_score\"] - df[\"baseline-f1_score\"]\n",
        "df[\"improvement_in_fourier\"] = df[\"fourier-f1_score\"] - df[\"baseline-f1_score\"]\n",
        "df = df.sort_values(by=\"improvement_in_fourier\", ascending=False)\n",
        "    \n",
        "                                "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d991b4ac",
      "metadata": {
        "id": "d991b4ac"
      },
      "source": [
        "## Results <a class=\"anchor\" id=\"results\">\n",
        "    \n",
        "In this section, we present the results\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c327c45d",
      "metadata": {
        "id": "c327c45d"
      },
      "source": [
        "### Print the raw results <a class=\"anchor\" id=\"raw-results\">\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ca40b2",
      "metadata": {
        "id": "31ca40b2",
        "outputId": "d814eddb-89db-4bc6-d2f5-82694cbb2ac1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>advanced-only-f1_score</th>\n",
              "      <th>fourier-f1_score</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.898661</td>\n",
              "      <td>0.898656</td>\n",
              "      <td>0.921899</td>\n",
              "      <td>0.637662</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.921899</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>0.917318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.005875</td>\n",
              "      <td>0.714117</td>\n",
              "      <td>0.712225</td>\n",
              "      <td>0.760910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.760910</td>\n",
              "      <td>0.708242</td>\n",
              "      <td>0.755035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292758</td>\n",
              "      <td>0.272309</td>\n",
              "      <td>0.472493</td>\n",
              "      <td>0.257285</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.472493</td>\n",
              "      <td>0.292758</td>\n",
              "      <td>0.472493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.161784</td>\n",
              "      <td>0.611146</td>\n",
              "      <td>0.552054</td>\n",
              "      <td>0.633867</td>\n",
              "      <td>0.055482</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.633867</td>\n",
              "      <td>0.449361</td>\n",
              "      <td>0.472083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.467311</td>\n",
              "      <td>0.605595</td>\n",
              "      <td>0.616349</td>\n",
              "      <td>0.908832</td>\n",
              "      <td>0.868069</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.908832</td>\n",
              "      <td>0.138284</td>\n",
              "      <td>0.441521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.464884</td>\n",
              "      <td>0.609782</td>\n",
              "      <td>0.620030</td>\n",
              "      <td>0.905097</td>\n",
              "      <td>0.773597</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.905097</td>\n",
              "      <td>0.144898</td>\n",
              "      <td>0.440214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.316378</td>\n",
              "      <td>0.502584</td>\n",
              "      <td>0.479199</td>\n",
              "      <td>0.728726</td>\n",
              "      <td>0.417406</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.728726</td>\n",
              "      <td>0.186206</td>\n",
              "      <td>0.412348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.316679</td>\n",
              "      <td>0.502386</td>\n",
              "      <td>0.480499</td>\n",
              "      <td>0.727329</td>\n",
              "      <td>0.489169</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.727329</td>\n",
              "      <td>0.185707</td>\n",
              "      <td>0.410649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.382287</td>\n",
              "      <td>0.362216</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.381661</td>\n",
              "      <td>0.408709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.149899</td>\n",
              "      <td>0.537321</td>\n",
              "      <td>0.446570</td>\n",
              "      <td>0.551929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.551929</td>\n",
              "      <td>0.387422</td>\n",
              "      <td>0.402030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.265837</td>\n",
              "      <td>0.432550</td>\n",
              "      <td>0.418242</td>\n",
              "      <td>0.642590</td>\n",
              "      <td>0.598314</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.642590</td>\n",
              "      <td>0.166712</td>\n",
              "      <td>0.376753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587878</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>0.924418</td>\n",
              "      <td>0.920543</td>\n",
              "      <td>0.794393</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>0.337556</td>\n",
              "      <td>0.332666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.065384</td>\n",
              "      <td>0.354876</td>\n",
              "      <td>0.296417</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.289491</td>\n",
              "      <td>0.305402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.039655</td>\n",
              "      <td>0.257104</td>\n",
              "      <td>0.247003</td>\n",
              "      <td>0.340035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.340035</td>\n",
              "      <td>0.217448</td>\n",
              "      <td>0.300380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.160633</td>\n",
              "      <td>0.350228</td>\n",
              "      <td>0.337734</td>\n",
              "      <td>0.446399</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.446399</td>\n",
              "      <td>0.189595</td>\n",
              "      <td>0.285766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.681420</td>\n",
              "      <td>0.812995</td>\n",
              "      <td>0.814203</td>\n",
              "      <td>0.950002</td>\n",
              "      <td>0.924162</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950002</td>\n",
              "      <td>0.131575</td>\n",
              "      <td>0.268582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.638073</td>\n",
              "      <td>0.776373</td>\n",
              "      <td>0.768875</td>\n",
              "      <td>0.867715</td>\n",
              "      <td>0.790066</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.867715</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.229642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.500479</td>\n",
              "      <td>0.710106</td>\n",
              "      <td>0.700725</td>\n",
              "      <td>0.714792</td>\n",
              "      <td>0.524028</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.714792</td>\n",
              "      <td>0.209627</td>\n",
              "      <td>0.214313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.775933</td>\n",
              "      <td>0.824412</td>\n",
              "      <td>0.826793</td>\n",
              "      <td>0.950620</td>\n",
              "      <td>0.929595</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950620</td>\n",
              "      <td>0.048479</td>\n",
              "      <td>0.174687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.776642</td>\n",
              "      <td>0.824534</td>\n",
              "      <td>0.828389</td>\n",
              "      <td>0.948914</td>\n",
              "      <td>0.879297</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.948914</td>\n",
              "      <td>0.047891</td>\n",
              "      <td>0.172272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377757</td>\n",
              "      <td>0.482497</td>\n",
              "      <td>0.461217</td>\n",
              "      <td>0.548595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.548595</td>\n",
              "      <td>0.104740</td>\n",
              "      <td>0.170838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377437</td>\n",
              "      <td>0.477236</td>\n",
              "      <td>0.457106</td>\n",
              "      <td>0.546473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.546473</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.169037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.027534</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.184179</td>\n",
              "      <td>-0.025282</td>\n",
              "      <td>0.156645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.836694</td>\n",
              "      <td>0.910886</td>\n",
              "      <td>0.912053</td>\n",
              "      <td>0.972387</td>\n",
              "      <td>0.959396</td>\n",
              "      <td>196912</td>\n",
              "      <td>98456</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.972387</td>\n",
              "      <td>0.074192</td>\n",
              "      <td>0.135693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.529180</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>0.659560</td>\n",
              "      <td>0.664630</td>\n",
              "      <td>0.552989</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>0.135883</td>\n",
              "      <td>0.135451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.495465</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>0.632402</td>\n",
              "      <td>0.622492</td>\n",
              "      <td>0.584808</td>\n",
              "      <td>126500</td>\n",
              "      <td>126500</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>0.140288</td>\n",
              "      <td>0.127027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>0.126062</td>\n",
              "      <td>0.121932</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>0.121932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.549603</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.668463</td>\n",
              "      <td>0.671308</td>\n",
              "      <td>0.596958</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.123339</td>\n",
              "      <td>0.121705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.687422</td>\n",
              "      <td>0.800804</td>\n",
              "      <td>0.776846</td>\n",
              "      <td>0.804012</td>\n",
              "      <td>0.663761</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.804012</td>\n",
              "      <td>0.113382</td>\n",
              "      <td>0.116590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.471829</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>0.592588</td>\n",
              "      <td>0.583752</td>\n",
              "      <td>0.574310</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>0.127071</td>\n",
              "      <td>0.111923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.734923</td>\n",
              "      <td>0.786622</td>\n",
              "      <td>0.785824</td>\n",
              "      <td>0.843251</td>\n",
              "      <td>0.805294</td>\n",
              "      <td>196912</td>\n",
              "      <td>196912</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.843251</td>\n",
              "      <td>0.051699</td>\n",
              "      <td>0.108327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.888158</td>\n",
              "      <td>0.954055</td>\n",
              "      <td>0.950162</td>\n",
              "      <td>0.981496</td>\n",
              "      <td>0.953674</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.981496</td>\n",
              "      <td>0.065897</td>\n",
              "      <td>0.093338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.886298</td>\n",
              "      <td>0.947860</td>\n",
              "      <td>0.943484</td>\n",
              "      <td>0.979017</td>\n",
              "      <td>0.953456</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.979017</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>0.092719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.726548</td>\n",
              "      <td>0.721765</td>\n",
              "      <td>0.715920</td>\n",
              "      <td>0.810750</td>\n",
              "      <td>0.767971</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.810750</td>\n",
              "      <td>-0.004783</td>\n",
              "      <td>0.084202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.727722</td>\n",
              "      <td>0.724755</td>\n",
              "      <td>0.716050</td>\n",
              "      <td>0.810304</td>\n",
              "      <td>0.783678</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.810304</td>\n",
              "      <td>-0.002966</td>\n",
              "      <td>0.082582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>0.853701</td>\n",
              "      <td>0.848081</td>\n",
              "      <td>0.897043</td>\n",
              "      <td>0.879696</td>\n",
              "      <td>323412</td>\n",
              "      <td>161706</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.897043</td>\n",
              "      <td>0.037565</td>\n",
              "      <td>0.080907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750413</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>0.830477</td>\n",
              "      <td>0.830932</td>\n",
              "      <td>0.789872</td>\n",
              "      <td>126500</td>\n",
              "      <td>63250</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>0.082615</td>\n",
              "      <td>0.080519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.696211</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>0.779493</td>\n",
              "      <td>0.773043</td>\n",
              "      <td>0.698988</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>0.084529</td>\n",
              "      <td>0.076832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.733211</td>\n",
              "      <td>0.783932</td>\n",
              "      <td>0.781025</td>\n",
              "      <td>0.805698</td>\n",
              "      <td>0.671462</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.805698</td>\n",
              "      <td>0.050721</td>\n",
              "      <td>0.072488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.941892</td>\n",
              "      <td>0.976060</td>\n",
              "      <td>0.973318</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.971464</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.034168</td>\n",
              "      <td>0.049327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.682685</td>\n",
              "      <td>0.687901</td>\n",
              "      <td>0.686720</td>\n",
              "      <td>0.728202</td>\n",
              "      <td>0.718802</td>\n",
              "      <td>323412</td>\n",
              "      <td>323412</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.728202</td>\n",
              "      <td>0.005216</td>\n",
              "      <td>0.045516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.715089</td>\n",
              "      <td>0.734014</td>\n",
              "      <td>0.714773</td>\n",
              "      <td>0.759578</td>\n",
              "      <td>0.618999</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.759578</td>\n",
              "      <td>0.018924</td>\n",
              "      <td>0.044489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.712207</td>\n",
              "      <td>0.731586</td>\n",
              "      <td>0.712605</td>\n",
              "      <td>0.755447</td>\n",
              "      <td>0.614337</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.755447</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.043241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.842512</td>\n",
              "      <td>0.856841</td>\n",
              "      <td>0.846741</td>\n",
              "      <td>0.869639</td>\n",
              "      <td>0.803801</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.869639</td>\n",
              "      <td>0.014329</td>\n",
              "      <td>0.027127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.647780</td>\n",
              "      <td>0.684058</td>\n",
              "      <td>0.688227</td>\n",
              "      <td>0.674901</td>\n",
              "      <td>0.646648</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.688227</td>\n",
              "      <td>0.036278</td>\n",
              "      <td>0.027121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.977943</td>\n",
              "      <td>0.996875</td>\n",
              "      <td>0.995622</td>\n",
              "      <td>0.998739</td>\n",
              "      <td>0.988729</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.998739</td>\n",
              "      <td>0.018932</td>\n",
              "      <td>0.020797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.985924</td>\n",
              "      <td>0.997995</td>\n",
              "      <td>0.996762</td>\n",
              "      <td>0.999207</td>\n",
              "      <td>0.993397</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999207</td>\n",
              "      <td>0.012072</td>\n",
              "      <td>0.013283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.989097</td>\n",
              "      <td>0.998672</td>\n",
              "      <td>0.997789</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.994636</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.010299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.992795</td>\n",
              "      <td>0.998939</td>\n",
              "      <td>0.998581</td>\n",
              "      <td>0.999555</td>\n",
              "      <td>0.996928</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999555</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.006760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>0.997624</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>0.998871</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.002255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.998388</td>\n",
              "      <td>0.999584</td>\n",
              "      <td>0.998534</td>\n",
              "      <td>0.999853</td>\n",
              "      <td>0.999169</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999853</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.001465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "39                        False                     False   \n",
              "41                        False                     False   \n",
              "35                        False                     False   \n",
              "10                        False                      True   \n",
              "0                         False                      True   \n",
              "27                        False                     False   \n",
              "29                        False                     False   \n",
              "2                         False                      True   \n",
              "30                        False                     False   \n",
              "37                        False                     False   \n",
              "33                        False                     False   \n",
              "42                        False                     False   \n",
              "43                        False                     False   \n",
              "31                        False                     False   \n",
              "34                        False                     False   \n",
              "6                         False                      True   \n",
              "8                         False                      True   \n",
              "44                        False                     False   \n",
              "18                        False                      True   \n",
              "45                        False                     False   \n",
              "28                        False                     False   \n",
              "1                         False                      True   \n",
              "40                        False                     False   \n",
              "24                        False                      True   \n",
              "46                        False                     False   \n",
              "52                        False                     False   \n",
              "32                        False                     False   \n",
              "19                        False                      True   \n",
              "16                        False                      True   \n",
              "49                        False                     False   \n",
              "51                        False                     False   \n",
              "9                         False                      True   \n",
              "36                        False                     False   \n",
              "47                        False                     False   \n",
              "20                        False                      True   \n",
              "26                        False                      True   \n",
              "25                        False                      True   \n",
              "48                        False                     False   \n",
              "7                         False                      True   \n",
              "15                        False                      True   \n",
              "53                        False                     False   \n",
              "38                        False                     False   \n",
              "11                        False                      True   \n",
              "17                        False                      True   \n",
              "50                        False                     False   \n",
              "3                         False                      True   \n",
              "5                         False                      True   \n",
              "21                        False                      True   \n",
              "23                        False                      True   \n",
              "12                        False                      True   \n",
              "14                        False                      True   \n",
              "13                        False                      True   \n",
              "22                        False                      True   \n",
              "4                         False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "39                 False                  True                     False   \n",
              "41                 False                  True                     False   \n",
              "35                  True                 False                     False   \n",
              "10                 False                  True                      True   \n",
              "0                   True                 False                      True   \n",
              "27                  True                 False                      True   \n",
              "29                  True                 False                      True   \n",
              "2                   True                 False                      True   \n",
              "30                  True                 False                     False   \n",
              "37                 False                  True                      True   \n",
              "33                  True                 False                     False   \n",
              "42                 False                  True                     False   \n",
              "43                 False                  True                     False   \n",
              "31                  True                 False                     False   \n",
              "34                  True                 False                     False   \n",
              "6                   True                 False                     False   \n",
              "8                   True                 False                     False   \n",
              "44                 False                  True                     False   \n",
              "18                 False                 False                      True   \n",
              "45                 False                 False                      True   \n",
              "28                  True                 False                      True   \n",
              "1                   True                 False                      True   \n",
              "40                 False                  True                     False   \n",
              "24                 False                 False                     False   \n",
              "46                 False                 False                      True   \n",
              "52                 False                 False                     False   \n",
              "32                  True                 False                     False   \n",
              "19                 False                 False                      True   \n",
              "16                 False                  True                     False   \n",
              "49                 False                 False                     False   \n",
              "51                 False                 False                     False   \n",
              "9                  False                  True                      True   \n",
              "36                 False                  True                      True   \n",
              "47                 False                 False                      True   \n",
              "20                 False                 False                      True   \n",
              "26                 False                 False                     False   \n",
              "25                 False                 False                     False   \n",
              "48                 False                 False                     False   \n",
              "7                   True                 False                     False   \n",
              "15                 False                  True                     False   \n",
              "53                 False                 False                     False   \n",
              "38                 False                  True                      True   \n",
              "11                 False                  True                      True   \n",
              "17                 False                  True                     False   \n",
              "50                 False                 False                     False   \n",
              "3                   True                 False                     False   \n",
              "5                   True                 False                     False   \n",
              "21                 False                 False                     False   \n",
              "23                 False                 False                     False   \n",
              "12                 False                  True                     False   \n",
              "14                 False                  True                     False   \n",
              "13                 False                  True                     False   \n",
              "22                 False                 False                     False   \n",
              "4                   True                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "39                         True          True            False   \n",
              "41                         True         False            False   \n",
              "35                        False         False            False   \n",
              "10                        False         False             True   \n",
              "0                         False          True            False   \n",
              "27                        False          True            False   \n",
              "29                        False         False            False   \n",
              "2                         False         False            False   \n",
              "30                         True          True            False   \n",
              "37                        False         False             True   \n",
              "33                        False          True            False   \n",
              "42                        False          True            False   \n",
              "43                        False         False             True   \n",
              "31                         True         False             True   \n",
              "34                        False         False             True   \n",
              "6                         False          True            False   \n",
              "8                         False         False            False   \n",
              "44                        False         False            False   \n",
              "18                        False          True            False   \n",
              "45                        False          True            False   \n",
              "28                        False         False             True   \n",
              "1                         False         False             True   \n",
              "40                         True         False             True   \n",
              "24                        False          True            False   \n",
              "46                        False         False             True   \n",
              "52                        False         False             True   \n",
              "32                         True         False            False   \n",
              "19                        False         False             True   \n",
              "16                        False         False             True   \n",
              "49                         True         False             True   \n",
              "51                        False          True            False   \n",
              "9                         False          True            False   \n",
              "36                        False          True            False   \n",
              "47                        False         False            False   \n",
              "20                        False         False            False   \n",
              "26                        False         False            False   \n",
              "25                        False         False             True   \n",
              "48                         True          True            False   \n",
              "7                         False         False             True   \n",
              "15                        False          True            False   \n",
              "53                        False         False            False   \n",
              "38                        False         False            False   \n",
              "11                        False         False            False   \n",
              "17                        False         False            False   \n",
              "50                         True         False            False   \n",
              "3                          True          True            False   \n",
              "5                          True         False            False   \n",
              "21                         True          True            False   \n",
              "23                         True         False            False   \n",
              "12                         True          True            False   \n",
              "14                         True         False            False   \n",
              "13                         True         False             True   \n",
              "22                         True         False             True   \n",
              "4                          True         False             True   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  advanced-only-f1_score  \\\n",
              "39           0.004581           0.898661                0.898656   \n",
              "41           0.005875           0.714117                0.712225   \n",
              "35           0.000000           0.292758                0.272309   \n",
              "10           0.161784           0.611146                0.552054   \n",
              "0            0.467311           0.605595                0.616349   \n",
              "27           0.464884           0.609782                0.620030   \n",
              "29           0.316378           0.502584                0.479199   \n",
              "2            0.316679           0.502386                0.480499   \n",
              "30           0.000626           0.382287                0.362216   \n",
              "37           0.149899           0.537321                0.446570   \n",
              "33           0.265837           0.432550                0.418242   \n",
              "42           0.587878           0.925433                0.924418   \n",
              "43           0.065384           0.354876                0.296417   \n",
              "31           0.039655           0.257104                0.247003   \n",
              "34           0.160633           0.350228                0.337734   \n",
              "6            0.681420           0.812995                0.814203   \n",
              "8            0.638073           0.776373                0.768875   \n",
              "44           0.500479           0.710106                0.700725   \n",
              "18           0.775933           0.824412                0.826793   \n",
              "45           0.776642           0.824534                0.828389   \n",
              "28           0.377757           0.482497                0.461217   \n",
              "1            0.377437           0.477236                0.457106   \n",
              "40           0.027534           0.002253                0.000000   \n",
              "24           0.836694           0.910886                0.912053   \n",
              "46           0.529180           0.665063                0.659560   \n",
              "52           0.495465           0.635753                0.632402   \n",
              "32           0.000000           0.132504                0.126062   \n",
              "19           0.549603           0.672941                0.668463   \n",
              "16           0.687422           0.800804                0.776846   \n",
              "49           0.471829           0.598900                0.592588   \n",
              "51           0.734923           0.786622                0.785824   \n",
              "9            0.888158           0.954055                0.950162   \n",
              "36           0.886298           0.947860                0.943484   \n",
              "47           0.726548           0.721765                0.715920   \n",
              "20           0.727722           0.724755                0.716050   \n",
              "26           0.816136           0.853701                0.848081   \n",
              "25           0.750413           0.833028                0.830477   \n",
              "48           0.696211           0.780740                0.779493   \n",
              "7            0.733211           0.783932                0.781025   \n",
              "15           0.941892           0.976060                0.973318   \n",
              "53           0.682685           0.687901                0.686720   \n",
              "38           0.715089           0.734014                0.714773   \n",
              "11           0.712207           0.731586                0.712605   \n",
              "17           0.842512           0.856841                0.846741   \n",
              "50           0.647780           0.684058                0.688227   \n",
              "3            0.977943           0.996875                0.995622   \n",
              "5            0.985924           0.997995                0.996762   \n",
              "21           0.989097           0.998672                0.997789   \n",
              "23           0.992795           0.998939                0.998581   \n",
              "12           0.997584           0.999435                0.997624   \n",
              "14           0.998388           0.999584                0.998534   \n",
              "13           1.000000           1.000000                1.000000   \n",
              "22           1.000000           1.000000                1.000000   \n",
              "4            1.000000           1.000000                1.000000   \n",
              "\n",
              "    fourier-f1_score  fourier-only-f1_score  n_encrypted  n_non_encrypted  \\\n",
              "39          0.921899               0.637662        49228           196912   \n",
              "41          0.760910               0.000000        80853           323412   \n",
              "35          0.472493               0.257285       161706           323412   \n",
              "10          0.633867               0.055482        31625            63250   \n",
              "0           0.908832               0.868069        49228            98456   \n",
              "27          0.905097               0.773597        49228           196912   \n",
              "29          0.728726               0.417406        80853           323412   \n",
              "2           0.727329               0.489169        80853           161706   \n",
              "30          0.409335               0.000000        49228           196912   \n",
              "37          0.551929               0.000000        31625           126500   \n",
              "33          0.642590               0.598314        98456           196912   \n",
              "42          0.920543               0.794393        98456           196912   \n",
              "43          0.370787               0.000000        63250           126500   \n",
              "31          0.340035               0.000000        31625           126500   \n",
              "34          0.446399               0.000000        63250           126500   \n",
              "6           0.950002               0.924162        98456            98456   \n",
              "8           0.867715               0.790066       161706           161706   \n",
              "44          0.714792               0.524028       161706           323412   \n",
              "18          0.950620               0.929595        98456            98456   \n",
              "45          0.948914               0.879297        98456           196912   \n",
              "28          0.548595               0.000000        31625           126500   \n",
              "1           0.546473               0.000000        31625            63250   \n",
              "40          0.184179               0.000000        31625           126500   \n",
              "24          0.972387               0.959396       196912            98456   \n",
              "46          0.664630               0.552989        63250           126500   \n",
              "52          0.622492               0.584808       126500           126500   \n",
              "32          0.121932               0.000000        80853           323412   \n",
              "19          0.671308               0.596958        63250            63250   \n",
              "16          0.804012               0.663761        63250            63250   \n",
              "49          0.583752               0.574310        63250           126500   \n",
              "51          0.843251               0.805294       196912           196912   \n",
              "9           0.981496               0.953674        49228            98456   \n",
              "36          0.979017               0.953456        49228           196912   \n",
              "47          0.810750               0.767971       161706           323412   \n",
              "20          0.810304               0.783678       161706           161706   \n",
              "26          0.897043               0.879696       323412           161706   \n",
              "25          0.830932               0.789872       126500            63250   \n",
              "48          0.773043               0.698988        98456           196912   \n",
              "7           0.805698               0.671462        63250            63250   \n",
              "15          0.991219               0.971464        98456            98456   \n",
              "53          0.728202               0.718802       323412           323412   \n",
              "38          0.759578               0.618999        80853           323412   \n",
              "11          0.755447               0.614337        80853           161706   \n",
              "17          0.869639               0.803801       161706           161706   \n",
              "50          0.674901               0.646648       161706           323412   \n",
              "3           0.998739               0.988729        49228            98456   \n",
              "5           0.999207               0.993397        80853           161706   \n",
              "21          0.999396               0.994636        98456            98456   \n",
              "23          0.999555               0.996928       161706           161706   \n",
              "12          0.999839               0.998871        49228            98456   \n",
              "14          0.999853               0.999169        80853           161706   \n",
              "13          1.000000               1.000000        31625            63250   \n",
              "22          1.000000               1.000000        63250            63250   \n",
              "4           1.000000               1.000000        31625            63250   \n",
              "\n",
              "    ratio_encrypt_nonencrypt  best_f1_score  improvement_in_advanced  \\\n",
              "39                      0.25       0.921899                 0.894079   \n",
              "41                      0.25       0.760910                 0.708242   \n",
              "35                      0.50       0.472493                 0.292758   \n",
              "10                      0.50       0.633867                 0.449361   \n",
              "0                       0.50       0.908832                 0.138284   \n",
              "27                      0.25       0.905097                 0.144898   \n",
              "29                      0.25       0.728726                 0.186206   \n",
              "2                       0.50       0.727329                 0.185707   \n",
              "30                      0.25       0.409335                 0.381661   \n",
              "37                      0.25       0.551929                 0.387422   \n",
              "33                      0.50       0.642590                 0.166712   \n",
              "42                      0.50       0.925433                 0.337556   \n",
              "43                      0.50       0.370787                 0.289491   \n",
              "31                      0.25       0.340035                 0.217448   \n",
              "34                      0.50       0.446399                 0.189595   \n",
              "6                       1.00       0.950002                 0.131575   \n",
              "8                       1.00       0.867715                 0.138300   \n",
              "44                      0.50       0.714792                 0.209627   \n",
              "18                      1.00       0.950620                 0.048479   \n",
              "45                      0.50       0.948914                 0.047891   \n",
              "28                      0.25       0.548595                 0.104740   \n",
              "1                       0.50       0.546473                 0.099800   \n",
              "40                      0.25       0.184179                -0.025282   \n",
              "24                      2.00       0.972387                 0.074192   \n",
              "46                      0.50       0.665063                 0.135883   \n",
              "52                      1.00       0.635753                 0.140288   \n",
              "32                      0.25       0.132504                 0.132504   \n",
              "19                      1.00       0.672941                 0.123339   \n",
              "16                      1.00       0.804012                 0.113382   \n",
              "49                      0.50       0.598900                 0.127071   \n",
              "51                      1.00       0.843251                 0.051699   \n",
              "9                       0.50       0.981496                 0.065897   \n",
              "36                      0.25       0.979017                 0.061563   \n",
              "47                      0.50       0.810750                -0.004783   \n",
              "20                      1.00       0.810304                -0.002966   \n",
              "26                      2.00       0.897043                 0.037565   \n",
              "25                      2.00       0.833028                 0.082615   \n",
              "48                      0.50       0.780740                 0.084529   \n",
              "7                       1.00       0.805698                 0.050721   \n",
              "15                      1.00       0.991219                 0.034168   \n",
              "53                      1.00       0.728202                 0.005216   \n",
              "38                      0.25       0.759578                 0.018924   \n",
              "11                      0.50       0.755447                 0.019380   \n",
              "17                      1.00       0.869639                 0.014329   \n",
              "50                      0.50       0.688227                 0.036278   \n",
              "3                       0.50       0.998739                 0.018932   \n",
              "5                       0.50       0.999207                 0.012072   \n",
              "21                      1.00       0.999396                 0.009575   \n",
              "23                      1.00       0.999555                 0.006143   \n",
              "12                      0.50       0.999839                 0.001851   \n",
              "14                      0.50       0.999853                 0.001196   \n",
              "13                      0.50       1.000000                 0.000000   \n",
              "22                      1.00       1.000000                 0.000000   \n",
              "4                       0.50       1.000000                 0.000000   \n",
              "\n",
              "    improvement_in_fourier  \n",
              "39                0.917318  \n",
              "41                0.755035  \n",
              "35                0.472493  \n",
              "10                0.472083  \n",
              "0                 0.441521  \n",
              "27                0.440214  \n",
              "29                0.412348  \n",
              "2                 0.410649  \n",
              "30                0.408709  \n",
              "37                0.402030  \n",
              "33                0.376753  \n",
              "42                0.332666  \n",
              "43                0.305402  \n",
              "31                0.300380  \n",
              "34                0.285766  \n",
              "6                 0.268582  \n",
              "8                 0.229642  \n",
              "44                0.214313  \n",
              "18                0.174687  \n",
              "45                0.172272  \n",
              "28                0.170838  \n",
              "1                 0.169037  \n",
              "40                0.156645  \n",
              "24                0.135693  \n",
              "46                0.135451  \n",
              "52                0.127027  \n",
              "32                0.121932  \n",
              "19                0.121705  \n",
              "16                0.116590  \n",
              "49                0.111923  \n",
              "51                0.108327  \n",
              "9                 0.093338  \n",
              "36                0.092719  \n",
              "47                0.084202  \n",
              "20                0.082582  \n",
              "26                0.080907  \n",
              "25                0.080519  \n",
              "48                0.076832  \n",
              "7                 0.072488  \n",
              "15                0.049327  \n",
              "53                0.045516  \n",
              "38                0.044489  \n",
              "11                0.043241  \n",
              "17                0.027127  \n",
              "50                0.027121  \n",
              "3                 0.020797  \n",
              "5                 0.013283  \n",
              "21                0.010299  \n",
              "23                0.006760  \n",
              "12                0.002255  \n",
              "14                0.001465  \n",
              "13                0.000000  \n",
              "22                0.000000  \n",
              "4                 0.000000  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0bcbd4",
      "metadata": {
        "id": "4c0bcbd4"
      },
      "outputs": [],
      "source": [
        "df.to_parquet(\"../comparison.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ba1b57",
      "metadata": {
        "id": "b2ba1b57"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by=\"improvement_in_fourier\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4886d3f",
      "metadata": {
        "id": "b4886d3f"
      },
      "source": [
        "### Sort by the improvement when using Fourier transforms over baseline <a class=\"anchor\" id=\"sorted-fourier\">\n",
        "\n",
        "We also take a few other things:\n",
        "* Room for improvement (1 - baseline score)\n",
        "* How much of the room for improvement was filled by fourier transforms (percentage)\n",
        "* Difference between F1 score with advanced and fourier\n",
        "        \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90696b1e",
      "metadata": {
        "id": "90696b1e",
        "outputId": "ee429206-bc91-4086-ecc4-d09961c72532"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.898661</td>\n",
              "      <td>...</td>\n",
              "      <td>0.637662</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.921899</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>0.917318</td>\n",
              "      <td>0.995419</td>\n",
              "      <td>0.023238</td>\n",
              "      <td>92.153936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.005875</td>\n",
              "      <td>0.714117</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.760910</td>\n",
              "      <td>0.708242</td>\n",
              "      <td>0.755035</td>\n",
              "      <td>0.994125</td>\n",
              "      <td>0.046793</td>\n",
              "      <td>75.949703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292758</td>\n",
              "      <td>...</td>\n",
              "      <td>0.257285</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.472493</td>\n",
              "      <td>0.292758</td>\n",
              "      <td>0.472493</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.179735</td>\n",
              "      <td>47.249312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.161784</td>\n",
              "      <td>0.611146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055482</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.633867</td>\n",
              "      <td>0.449361</td>\n",
              "      <td>0.472083</td>\n",
              "      <td>0.838216</td>\n",
              "      <td>0.022722</td>\n",
              "      <td>56.319967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.467311</td>\n",
              "      <td>0.605595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868069</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.908832</td>\n",
              "      <td>0.138284</td>\n",
              "      <td>0.441521</td>\n",
              "      <td>0.532689</td>\n",
              "      <td>0.303237</td>\n",
              "      <td>82.885331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.464884</td>\n",
              "      <td>0.609782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.773597</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.905097</td>\n",
              "      <td>0.144898</td>\n",
              "      <td>0.440214</td>\n",
              "      <td>0.535116</td>\n",
              "      <td>0.295315</td>\n",
              "      <td>82.265032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.316378</td>\n",
              "      <td>0.502584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.417406</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.728726</td>\n",
              "      <td>0.186206</td>\n",
              "      <td>0.412348</td>\n",
              "      <td>0.683622</td>\n",
              "      <td>0.226142</td>\n",
              "      <td>60.318122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.316679</td>\n",
              "      <td>0.502386</td>\n",
              "      <td>...</td>\n",
              "      <td>0.489169</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.727329</td>\n",
              "      <td>0.185707</td>\n",
              "      <td>0.410649</td>\n",
              "      <td>0.683321</td>\n",
              "      <td>0.224942</td>\n",
              "      <td>60.096141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.382287</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.381661</td>\n",
              "      <td>0.408709</td>\n",
              "      <td>0.999374</td>\n",
              "      <td>0.027048</td>\n",
              "      <td>40.896531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.149899</td>\n",
              "      <td>0.537321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.551929</td>\n",
              "      <td>0.387422</td>\n",
              "      <td>0.402030</td>\n",
              "      <td>0.850101</td>\n",
              "      <td>0.014608</td>\n",
              "      <td>47.292049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.265837</td>\n",
              "      <td>0.432550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.598314</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.642590</td>\n",
              "      <td>0.166712</td>\n",
              "      <td>0.376753</td>\n",
              "      <td>0.734163</td>\n",
              "      <td>0.210041</td>\n",
              "      <td>51.317359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587878</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>...</td>\n",
              "      <td>0.794393</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>0.337556</td>\n",
              "      <td>0.332666</td>\n",
              "      <td>0.412122</td>\n",
              "      <td>-0.004890</td>\n",
              "      <td>80.720096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.065384</td>\n",
              "      <td>0.354876</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.289491</td>\n",
              "      <td>0.305402</td>\n",
              "      <td>0.934616</td>\n",
              "      <td>0.015911</td>\n",
              "      <td>32.676763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.039655</td>\n",
              "      <td>0.257104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.340035</td>\n",
              "      <td>0.217448</td>\n",
              "      <td>0.300380</td>\n",
              "      <td>0.960345</td>\n",
              "      <td>0.082931</td>\n",
              "      <td>31.278309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.160633</td>\n",
              "      <td>0.350228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.446399</td>\n",
              "      <td>0.189595</td>\n",
              "      <td>0.285766</td>\n",
              "      <td>0.839367</td>\n",
              "      <td>0.096172</td>\n",
              "      <td>34.045465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.681420</td>\n",
              "      <td>0.812995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924162</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950002</td>\n",
              "      <td>0.131575</td>\n",
              "      <td>0.268582</td>\n",
              "      <td>0.318580</td>\n",
              "      <td>0.137007</td>\n",
              "      <td>84.305973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.638073</td>\n",
              "      <td>0.776373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.790066</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.867715</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.229642</td>\n",
              "      <td>0.361927</td>\n",
              "      <td>0.091342</td>\n",
              "      <td>63.449847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.500479</td>\n",
              "      <td>0.710106</td>\n",
              "      <td>...</td>\n",
              "      <td>0.524028</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.714792</td>\n",
              "      <td>0.209627</td>\n",
              "      <td>0.214313</td>\n",
              "      <td>0.499521</td>\n",
              "      <td>0.004686</td>\n",
              "      <td>42.903676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.775933</td>\n",
              "      <td>0.824412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.929595</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950620</td>\n",
              "      <td>0.048479</td>\n",
              "      <td>0.174687</td>\n",
              "      <td>0.224067</td>\n",
              "      <td>0.126208</td>\n",
              "      <td>77.962073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.776642</td>\n",
              "      <td>0.824534</td>\n",
              "      <td>...</td>\n",
              "      <td>0.879297</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.948914</td>\n",
              "      <td>0.047891</td>\n",
              "      <td>0.172272</td>\n",
              "      <td>0.223358</td>\n",
              "      <td>0.124381</td>\n",
              "      <td>77.128363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377757</td>\n",
              "      <td>0.482497</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.548595</td>\n",
              "      <td>0.104740</td>\n",
              "      <td>0.170838</td>\n",
              "      <td>0.622243</td>\n",
              "      <td>0.066098</td>\n",
              "      <td>27.455162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377437</td>\n",
              "      <td>0.477236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.546473</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.169037</td>\n",
              "      <td>0.622563</td>\n",
              "      <td>0.069237</td>\n",
              "      <td>27.151717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.027534</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.184179</td>\n",
              "      <td>-0.025282</td>\n",
              "      <td>0.156645</td>\n",
              "      <td>0.972466</td>\n",
              "      <td>0.181927</td>\n",
              "      <td>16.108055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.836694</td>\n",
              "      <td>0.910886</td>\n",
              "      <td>...</td>\n",
              "      <td>0.959396</td>\n",
              "      <td>196912</td>\n",
              "      <td>98456</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.972387</td>\n",
              "      <td>0.074192</td>\n",
              "      <td>0.135693</td>\n",
              "      <td>0.163306</td>\n",
              "      <td>0.061501</td>\n",
              "      <td>83.091218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.529180</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.552989</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>0.135883</td>\n",
              "      <td>0.135451</td>\n",
              "      <td>0.470820</td>\n",
              "      <td>-0.000433</td>\n",
              "      <td>28.769094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.495465</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.584808</td>\n",
              "      <td>126500</td>\n",
              "      <td>126500</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>0.140288</td>\n",
              "      <td>0.127027</td>\n",
              "      <td>0.504535</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>25.177032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>0.121932</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.010572</td>\n",
              "      <td>12.193211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.549603</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>...</td>\n",
              "      <td>0.596958</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.123339</td>\n",
              "      <td>0.121705</td>\n",
              "      <td>0.450397</td>\n",
              "      <td>-0.001633</td>\n",
              "      <td>27.021764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.687422</td>\n",
              "      <td>0.800804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.663761</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.804012</td>\n",
              "      <td>0.113382</td>\n",
              "      <td>0.116590</td>\n",
              "      <td>0.312578</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>37.299595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.471829</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>...</td>\n",
              "      <td>0.574310</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>0.127071</td>\n",
              "      <td>0.111923</td>\n",
              "      <td>0.528171</td>\n",
              "      <td>-0.015148</td>\n",
              "      <td>21.190624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.734923</td>\n",
              "      <td>0.786622</td>\n",
              "      <td>...</td>\n",
              "      <td>0.805294</td>\n",
              "      <td>196912</td>\n",
              "      <td>196912</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.843251</td>\n",
              "      <td>0.051699</td>\n",
              "      <td>0.108327</td>\n",
              "      <td>0.265077</td>\n",
              "      <td>0.056628</td>\n",
              "      <td>40.866396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.888158</td>\n",
              "      <td>0.954055</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953674</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.981496</td>\n",
              "      <td>0.065897</td>\n",
              "      <td>0.093338</td>\n",
              "      <td>0.111842</td>\n",
              "      <td>0.027441</td>\n",
              "      <td>83.454913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.886298</td>\n",
              "      <td>0.947860</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953456</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.979017</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>0.092719</td>\n",
              "      <td>0.113702</td>\n",
              "      <td>0.031157</td>\n",
              "      <td>81.545656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.726548</td>\n",
              "      <td>0.721765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.767971</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.810750</td>\n",
              "      <td>-0.004783</td>\n",
              "      <td>0.084202</td>\n",
              "      <td>0.273452</td>\n",
              "      <td>0.088985</td>\n",
              "      <td>30.792269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.727722</td>\n",
              "      <td>0.724755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.783678</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.810304</td>\n",
              "      <td>-0.002966</td>\n",
              "      <td>0.082582</td>\n",
              "      <td>0.272278</td>\n",
              "      <td>0.085548</td>\n",
              "      <td>30.330069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>0.853701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.879696</td>\n",
              "      <td>323412</td>\n",
              "      <td>161706</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.897043</td>\n",
              "      <td>0.037565</td>\n",
              "      <td>0.080907</td>\n",
              "      <td>0.183864</td>\n",
              "      <td>0.043342</td>\n",
              "      <td>44.003928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750413</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789872</td>\n",
              "      <td>126500</td>\n",
              "      <td>63250</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>0.082615</td>\n",
              "      <td>0.080519</td>\n",
              "      <td>0.249587</td>\n",
              "      <td>-0.002096</td>\n",
              "      <td>32.260734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.696211</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.698988</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>0.084529</td>\n",
              "      <td>0.076832</td>\n",
              "      <td>0.303789</td>\n",
              "      <td>-0.007697</td>\n",
              "      <td>25.291312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.733211</td>\n",
              "      <td>0.783932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.671462</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.805698</td>\n",
              "      <td>0.050721</td>\n",
              "      <td>0.072488</td>\n",
              "      <td>0.266789</td>\n",
              "      <td>0.021766</td>\n",
              "      <td>27.170422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.941892</td>\n",
              "      <td>0.976060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.971464</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.034168</td>\n",
              "      <td>0.049327</td>\n",
              "      <td>0.058108</td>\n",
              "      <td>0.015159</td>\n",
              "      <td>84.888337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.682685</td>\n",
              "      <td>0.687901</td>\n",
              "      <td>...</td>\n",
              "      <td>0.718802</td>\n",
              "      <td>323412</td>\n",
              "      <td>323412</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.728202</td>\n",
              "      <td>0.005216</td>\n",
              "      <td>0.045516</td>\n",
              "      <td>0.317315</td>\n",
              "      <td>0.040301</td>\n",
              "      <td>14.344259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.715089</td>\n",
              "      <td>0.734014</td>\n",
              "      <td>...</td>\n",
              "      <td>0.618999</td>\n",
              "      <td>80853</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.759578</td>\n",
              "      <td>0.018924</td>\n",
              "      <td>0.044489</td>\n",
              "      <td>0.284911</td>\n",
              "      <td>0.025564</td>\n",
              "      <td>15.614927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.712207</td>\n",
              "      <td>0.731586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.614337</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.755447</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.043241</td>\n",
              "      <td>0.287793</td>\n",
              "      <td>0.023861</td>\n",
              "      <td>15.024881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.842512</td>\n",
              "      <td>0.856841</td>\n",
              "      <td>...</td>\n",
              "      <td>0.803801</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.869639</td>\n",
              "      <td>0.014329</td>\n",
              "      <td>0.027127</td>\n",
              "      <td>0.157488</td>\n",
              "      <td>0.012798</td>\n",
              "      <td>17.224592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.647780</td>\n",
              "      <td>0.684058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.646648</td>\n",
              "      <td>161706</td>\n",
              "      <td>323412</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.688227</td>\n",
              "      <td>0.036278</td>\n",
              "      <td>0.027121</td>\n",
              "      <td>0.352220</td>\n",
              "      <td>-0.009156</td>\n",
              "      <td>7.700139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.977943</td>\n",
              "      <td>0.996875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.988729</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.998739</td>\n",
              "      <td>0.018932</td>\n",
              "      <td>0.020797</td>\n",
              "      <td>0.022057</td>\n",
              "      <td>0.001865</td>\n",
              "      <td>94.283858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.985924</td>\n",
              "      <td>0.997995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993397</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999207</td>\n",
              "      <td>0.012072</td>\n",
              "      <td>0.013283</td>\n",
              "      <td>0.014076</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>94.368169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.989097</td>\n",
              "      <td>0.998672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994636</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.010299</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>94.461093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.992795</td>\n",
              "      <td>0.998939</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996928</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999555</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>93.829816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.998871</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.002416</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>93.318266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.998388</td>\n",
              "      <td>0.999584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999169</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999853</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>90.895747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "39                        False                     False   \n",
              "41                        False                     False   \n",
              "35                        False                     False   \n",
              "10                        False                      True   \n",
              "0                         False                      True   \n",
              "27                        False                     False   \n",
              "29                        False                     False   \n",
              "2                         False                      True   \n",
              "30                        False                     False   \n",
              "37                        False                     False   \n",
              "33                        False                     False   \n",
              "42                        False                     False   \n",
              "43                        False                     False   \n",
              "31                        False                     False   \n",
              "34                        False                     False   \n",
              "6                         False                      True   \n",
              "8                         False                      True   \n",
              "44                        False                     False   \n",
              "18                        False                      True   \n",
              "45                        False                     False   \n",
              "28                        False                     False   \n",
              "1                         False                      True   \n",
              "40                        False                     False   \n",
              "24                        False                      True   \n",
              "46                        False                     False   \n",
              "52                        False                     False   \n",
              "32                        False                     False   \n",
              "19                        False                      True   \n",
              "16                        False                      True   \n",
              "49                        False                     False   \n",
              "51                        False                     False   \n",
              "9                         False                      True   \n",
              "36                        False                     False   \n",
              "47                        False                     False   \n",
              "20                        False                      True   \n",
              "26                        False                      True   \n",
              "25                        False                      True   \n",
              "48                        False                     False   \n",
              "7                         False                      True   \n",
              "15                        False                      True   \n",
              "53                        False                     False   \n",
              "38                        False                     False   \n",
              "11                        False                      True   \n",
              "17                        False                      True   \n",
              "50                        False                     False   \n",
              "3                         False                      True   \n",
              "5                         False                      True   \n",
              "21                        False                      True   \n",
              "23                        False                      True   \n",
              "12                        False                      True   \n",
              "14                        False                      True   \n",
              "13                        False                      True   \n",
              "22                        False                      True   \n",
              "4                         False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "39                 False                  True                     False   \n",
              "41                 False                  True                     False   \n",
              "35                  True                 False                     False   \n",
              "10                 False                  True                      True   \n",
              "0                   True                 False                      True   \n",
              "27                  True                 False                      True   \n",
              "29                  True                 False                      True   \n",
              "2                   True                 False                      True   \n",
              "30                  True                 False                     False   \n",
              "37                 False                  True                      True   \n",
              "33                  True                 False                     False   \n",
              "42                 False                  True                     False   \n",
              "43                 False                  True                     False   \n",
              "31                  True                 False                     False   \n",
              "34                  True                 False                     False   \n",
              "6                   True                 False                     False   \n",
              "8                   True                 False                     False   \n",
              "44                 False                  True                     False   \n",
              "18                 False                 False                      True   \n",
              "45                 False                 False                      True   \n",
              "28                  True                 False                      True   \n",
              "1                   True                 False                      True   \n",
              "40                 False                  True                     False   \n",
              "24                 False                 False                     False   \n",
              "46                 False                 False                      True   \n",
              "52                 False                 False                     False   \n",
              "32                  True                 False                     False   \n",
              "19                 False                 False                      True   \n",
              "16                 False                  True                     False   \n",
              "49                 False                 False                     False   \n",
              "51                 False                 False                     False   \n",
              "9                  False                  True                      True   \n",
              "36                 False                  True                      True   \n",
              "47                 False                 False                      True   \n",
              "20                 False                 False                      True   \n",
              "26                 False                 False                     False   \n",
              "25                 False                 False                     False   \n",
              "48                 False                 False                     False   \n",
              "7                   True                 False                     False   \n",
              "15                 False                  True                     False   \n",
              "53                 False                 False                     False   \n",
              "38                 False                  True                      True   \n",
              "11                 False                  True                      True   \n",
              "17                 False                  True                     False   \n",
              "50                 False                 False                     False   \n",
              "3                   True                 False                     False   \n",
              "5                   True                 False                     False   \n",
              "21                 False                 False                     False   \n",
              "23                 False                 False                     False   \n",
              "12                 False                  True                     False   \n",
              "14                 False                  True                     False   \n",
              "13                 False                  True                     False   \n",
              "22                 False                 False                     False   \n",
              "4                   True                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "39                         True          True            False   \n",
              "41                         True         False            False   \n",
              "35                        False         False            False   \n",
              "10                        False         False             True   \n",
              "0                         False          True            False   \n",
              "27                        False          True            False   \n",
              "29                        False         False            False   \n",
              "2                         False         False            False   \n",
              "30                         True          True            False   \n",
              "37                        False         False             True   \n",
              "33                        False          True            False   \n",
              "42                        False          True            False   \n",
              "43                        False         False             True   \n",
              "31                         True         False             True   \n",
              "34                        False         False             True   \n",
              "6                         False          True            False   \n",
              "8                         False         False            False   \n",
              "44                        False         False            False   \n",
              "18                        False          True            False   \n",
              "45                        False          True            False   \n",
              "28                        False         False             True   \n",
              "1                         False         False             True   \n",
              "40                         True         False             True   \n",
              "24                        False          True            False   \n",
              "46                        False         False             True   \n",
              "52                        False         False             True   \n",
              "32                         True         False            False   \n",
              "19                        False         False             True   \n",
              "16                        False         False             True   \n",
              "49                         True         False             True   \n",
              "51                        False          True            False   \n",
              "9                         False          True            False   \n",
              "36                        False          True            False   \n",
              "47                        False         False            False   \n",
              "20                        False         False            False   \n",
              "26                        False         False            False   \n",
              "25                        False         False             True   \n",
              "48                         True          True            False   \n",
              "7                         False         False             True   \n",
              "15                        False          True            False   \n",
              "53                        False         False            False   \n",
              "38                        False         False            False   \n",
              "11                        False         False            False   \n",
              "17                        False         False            False   \n",
              "50                         True         False            False   \n",
              "3                          True          True            False   \n",
              "5                          True         False            False   \n",
              "21                         True          True            False   \n",
              "23                         True         False            False   \n",
              "12                         True          True            False   \n",
              "14                         True         False            False   \n",
              "13                         True         False             True   \n",
              "22                         True         False             True   \n",
              "4                          True         False             True   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "39           0.004581           0.898661  ...               0.637662   \n",
              "41           0.005875           0.714117  ...               0.000000   \n",
              "35           0.000000           0.292758  ...               0.257285   \n",
              "10           0.161784           0.611146  ...               0.055482   \n",
              "0            0.467311           0.605595  ...               0.868069   \n",
              "27           0.464884           0.609782  ...               0.773597   \n",
              "29           0.316378           0.502584  ...               0.417406   \n",
              "2            0.316679           0.502386  ...               0.489169   \n",
              "30           0.000626           0.382287  ...               0.000000   \n",
              "37           0.149899           0.537321  ...               0.000000   \n",
              "33           0.265837           0.432550  ...               0.598314   \n",
              "42           0.587878           0.925433  ...               0.794393   \n",
              "43           0.065384           0.354876  ...               0.000000   \n",
              "31           0.039655           0.257104  ...               0.000000   \n",
              "34           0.160633           0.350228  ...               0.000000   \n",
              "6            0.681420           0.812995  ...               0.924162   \n",
              "8            0.638073           0.776373  ...               0.790066   \n",
              "44           0.500479           0.710106  ...               0.524028   \n",
              "18           0.775933           0.824412  ...               0.929595   \n",
              "45           0.776642           0.824534  ...               0.879297   \n",
              "28           0.377757           0.482497  ...               0.000000   \n",
              "1            0.377437           0.477236  ...               0.000000   \n",
              "40           0.027534           0.002253  ...               0.000000   \n",
              "24           0.836694           0.910886  ...               0.959396   \n",
              "46           0.529180           0.665063  ...               0.552989   \n",
              "52           0.495465           0.635753  ...               0.584808   \n",
              "32           0.000000           0.132504  ...               0.000000   \n",
              "19           0.549603           0.672941  ...               0.596958   \n",
              "16           0.687422           0.800804  ...               0.663761   \n",
              "49           0.471829           0.598900  ...               0.574310   \n",
              "51           0.734923           0.786622  ...               0.805294   \n",
              "9            0.888158           0.954055  ...               0.953674   \n",
              "36           0.886298           0.947860  ...               0.953456   \n",
              "47           0.726548           0.721765  ...               0.767971   \n",
              "20           0.727722           0.724755  ...               0.783678   \n",
              "26           0.816136           0.853701  ...               0.879696   \n",
              "25           0.750413           0.833028  ...               0.789872   \n",
              "48           0.696211           0.780740  ...               0.698988   \n",
              "7            0.733211           0.783932  ...               0.671462   \n",
              "15           0.941892           0.976060  ...               0.971464   \n",
              "53           0.682685           0.687901  ...               0.718802   \n",
              "38           0.715089           0.734014  ...               0.618999   \n",
              "11           0.712207           0.731586  ...               0.614337   \n",
              "17           0.842512           0.856841  ...               0.803801   \n",
              "50           0.647780           0.684058  ...               0.646648   \n",
              "3            0.977943           0.996875  ...               0.988729   \n",
              "5            0.985924           0.997995  ...               0.993397   \n",
              "21           0.989097           0.998672  ...               0.994636   \n",
              "23           0.992795           0.998939  ...               0.996928   \n",
              "12           0.997584           0.999435  ...               0.998871   \n",
              "14           0.998388           0.999584  ...               0.999169   \n",
              "13           1.000000           1.000000  ...               1.000000   \n",
              "22           1.000000           1.000000  ...               1.000000   \n",
              "4            1.000000           1.000000  ...               1.000000   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "39        49228           196912                      0.25       0.921899   \n",
              "41        80853           323412                      0.25       0.760910   \n",
              "35       161706           323412                      0.50       0.472493   \n",
              "10        31625            63250                      0.50       0.633867   \n",
              "0         49228            98456                      0.50       0.908832   \n",
              "27        49228           196912                      0.25       0.905097   \n",
              "29        80853           323412                      0.25       0.728726   \n",
              "2         80853           161706                      0.50       0.727329   \n",
              "30        49228           196912                      0.25       0.409335   \n",
              "37        31625           126500                      0.25       0.551929   \n",
              "33        98456           196912                      0.50       0.642590   \n",
              "42        98456           196912                      0.50       0.925433   \n",
              "43        63250           126500                      0.50       0.370787   \n",
              "31        31625           126500                      0.25       0.340035   \n",
              "34        63250           126500                      0.50       0.446399   \n",
              "6         98456            98456                      1.00       0.950002   \n",
              "8        161706           161706                      1.00       0.867715   \n",
              "44       161706           323412                      0.50       0.714792   \n",
              "18        98456            98456                      1.00       0.950620   \n",
              "45        98456           196912                      0.50       0.948914   \n",
              "28        31625           126500                      0.25       0.548595   \n",
              "1         31625            63250                      0.50       0.546473   \n",
              "40        31625           126500                      0.25       0.184179   \n",
              "24       196912            98456                      2.00       0.972387   \n",
              "46        63250           126500                      0.50       0.665063   \n",
              "52       126500           126500                      1.00       0.635753   \n",
              "32        80853           323412                      0.25       0.132504   \n",
              "19        63250            63250                      1.00       0.672941   \n",
              "16        63250            63250                      1.00       0.804012   \n",
              "49        63250           126500                      0.50       0.598900   \n",
              "51       196912           196912                      1.00       0.843251   \n",
              "9         49228            98456                      0.50       0.981496   \n",
              "36        49228           196912                      0.25       0.979017   \n",
              "47       161706           323412                      0.50       0.810750   \n",
              "20       161706           161706                      1.00       0.810304   \n",
              "26       323412           161706                      2.00       0.897043   \n",
              "25       126500            63250                      2.00       0.833028   \n",
              "48        98456           196912                      0.50       0.780740   \n",
              "7         63250            63250                      1.00       0.805698   \n",
              "15        98456            98456                      1.00       0.991219   \n",
              "53       323412           323412                      1.00       0.728202   \n",
              "38        80853           323412                      0.25       0.759578   \n",
              "11        80853           161706                      0.50       0.755447   \n",
              "17       161706           161706                      1.00       0.869639   \n",
              "50       161706           323412                      0.50       0.688227   \n",
              "3         49228            98456                      0.50       0.998739   \n",
              "5         80853           161706                      0.50       0.999207   \n",
              "21        98456            98456                      1.00       0.999396   \n",
              "23       161706           161706                      1.00       0.999555   \n",
              "12        49228            98456                      0.50       0.999839   \n",
              "14        80853           161706                      0.50       0.999853   \n",
              "13        31625            63250                      0.50       1.000000   \n",
              "22        63250            63250                      1.00       1.000000   \n",
              "4         31625            63250                      0.50       1.000000   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "39                 0.894079                0.917318              0.995419   \n",
              "41                 0.708242                0.755035              0.994125   \n",
              "35                 0.292758                0.472493              1.000000   \n",
              "10                 0.449361                0.472083              0.838216   \n",
              "0                  0.138284                0.441521              0.532689   \n",
              "27                 0.144898                0.440214              0.535116   \n",
              "29                 0.186206                0.412348              0.683622   \n",
              "2                  0.185707                0.410649              0.683321   \n",
              "30                 0.381661                0.408709              0.999374   \n",
              "37                 0.387422                0.402030              0.850101   \n",
              "33                 0.166712                0.376753              0.734163   \n",
              "42                 0.337556                0.332666              0.412122   \n",
              "43                 0.289491                0.305402              0.934616   \n",
              "31                 0.217448                0.300380              0.960345   \n",
              "34                 0.189595                0.285766              0.839367   \n",
              "6                  0.131575                0.268582              0.318580   \n",
              "8                  0.138300                0.229642              0.361927   \n",
              "44                 0.209627                0.214313              0.499521   \n",
              "18                 0.048479                0.174687              0.224067   \n",
              "45                 0.047891                0.172272              0.223358   \n",
              "28                 0.104740                0.170838              0.622243   \n",
              "1                  0.099800                0.169037              0.622563   \n",
              "40                -0.025282                0.156645              0.972466   \n",
              "24                 0.074192                0.135693              0.163306   \n",
              "46                 0.135883                0.135451              0.470820   \n",
              "52                 0.140288                0.127027              0.504535   \n",
              "32                 0.132504                0.121932              1.000000   \n",
              "19                 0.123339                0.121705              0.450397   \n",
              "16                 0.113382                0.116590              0.312578   \n",
              "49                 0.127071                0.111923              0.528171   \n",
              "51                 0.051699                0.108327              0.265077   \n",
              "9                  0.065897                0.093338              0.111842   \n",
              "36                 0.061563                0.092719              0.113702   \n",
              "47                -0.004783                0.084202              0.273452   \n",
              "20                -0.002966                0.082582              0.272278   \n",
              "26                 0.037565                0.080907              0.183864   \n",
              "25                 0.082615                0.080519              0.249587   \n",
              "48                 0.084529                0.076832              0.303789   \n",
              "7                  0.050721                0.072488              0.266789   \n",
              "15                 0.034168                0.049327              0.058108   \n",
              "53                 0.005216                0.045516              0.317315   \n",
              "38                 0.018924                0.044489              0.284911   \n",
              "11                 0.019380                0.043241              0.287793   \n",
              "17                 0.014329                0.027127              0.157488   \n",
              "50                 0.036278                0.027121              0.352220   \n",
              "3                  0.018932                0.020797              0.022057   \n",
              "5                  0.012072                0.013283              0.014076   \n",
              "21                 0.009575                0.010299              0.010903   \n",
              "23                 0.006143                0.006760              0.007205   \n",
              "12                 0.001851                0.002255              0.002416   \n",
              "14                 0.001196                0.001465              0.001612   \n",
              "13                 0.000000                0.000000              0.000000   \n",
              "22                 0.000000                0.000000              0.000000   \n",
              "4                  0.000000                0.000000              0.000000   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "39                0.023238                  92.153936  \n",
              "41                0.046793                  75.949703  \n",
              "35                0.179735                  47.249312  \n",
              "10                0.022722                  56.319967  \n",
              "0                 0.303237                  82.885331  \n",
              "27                0.295315                  82.265032  \n",
              "29                0.226142                  60.318122  \n",
              "2                 0.224942                  60.096141  \n",
              "30                0.027048                  40.896531  \n",
              "37                0.014608                  47.292049  \n",
              "33                0.210041                  51.317359  \n",
              "42               -0.004890                  80.720096  \n",
              "43                0.015911                  32.676763  \n",
              "31                0.082931                  31.278309  \n",
              "34                0.096172                  34.045465  \n",
              "6                 0.137007                  84.305973  \n",
              "8                 0.091342                  63.449847  \n",
              "44                0.004686                  42.903676  \n",
              "18                0.126208                  77.962073  \n",
              "45                0.124381                  77.128363  \n",
              "28                0.066098                  27.455162  \n",
              "1                 0.069237                  27.151717  \n",
              "40                0.181927                  16.108055  \n",
              "24                0.061501                  83.091218  \n",
              "46               -0.000433                  28.769094  \n",
              "52               -0.013261                  25.177032  \n",
              "32               -0.010572                  12.193211  \n",
              "19               -0.001633                  27.021764  \n",
              "16                0.003208                  37.299595  \n",
              "49               -0.015148                  21.190624  \n",
              "51                0.056628                  40.866396  \n",
              "9                 0.027441                  83.454913  \n",
              "36                0.031157                  81.545656  \n",
              "47                0.088985                  30.792269  \n",
              "20                0.085548                  30.330069  \n",
              "26                0.043342                  44.003928  \n",
              "25               -0.002096                  32.260734  \n",
              "48               -0.007697                  25.291312  \n",
              "7                 0.021766                  27.170422  \n",
              "15                0.015159                  84.888337  \n",
              "53                0.040301                  14.344259  \n",
              "38                0.025564                  15.614927  \n",
              "11                0.023861                  15.024881  \n",
              "17                0.012798                  17.224592  \n",
              "50               -0.009156                   7.700139  \n",
              "3                 0.001865                  94.283858  \n",
              "5                 0.001212                  94.368169  \n",
              "21                0.000724                  94.461093  \n",
              "23                0.000617                  93.829816  \n",
              "12                0.000403                  93.318266  \n",
              "14                0.000269                  90.895747  \n",
              "13                0.000000                        NaN  \n",
              "22                0.000000                        NaN  \n",
              "4                 0.000000                        NaN  \n",
              "\n",
              "[54 rows x 22 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"improvement_in_advanced\"] = df[\"advanced-f1_score\"] - df[\"baseline-f1_score\"]\n",
        "df[\"room_for_improvement\"] = 1.0 - df[\"baseline-f1_score\"]\n",
        "df[\"fourier_minus_advanced\"] = df[\"fourier-f1_score\"] - df[\"advanced-f1_score\"]\n",
        "df[\"percentage_of_room_filled\"] = df[\"improvement_in_fourier\"] * 100.0 / df[\"room_for_improvement\"]\n",
        "#df.sort_values(by=\"fourier_minus_advanced\", ascending=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c37fa14",
      "metadata": {
        "id": "1c37fa14"
      },
      "source": [
        "### Measure improvement when only webp files are used <a class=\"anchor\" id=\"webp-only\">\n",
        "\n",
        "We want to measure this alone because in the literature, poor performance in webp files has been mentioned\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31ac58a",
      "metadata": {
        "id": "e31ac58a",
        "outputId": "89a90bf3-7e51-4d01-95af-58bcba855131"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.161784</td>\n",
              "      <td>0.611146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055482</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.633867</td>\n",
              "      <td>0.449361</td>\n",
              "      <td>0.472083</td>\n",
              "      <td>0.838216</td>\n",
              "      <td>0.022722</td>\n",
              "      <td>56.319967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.149899</td>\n",
              "      <td>0.537321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.551929</td>\n",
              "      <td>0.387422</td>\n",
              "      <td>0.402030</td>\n",
              "      <td>0.850101</td>\n",
              "      <td>0.014608</td>\n",
              "      <td>47.292049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.065384</td>\n",
              "      <td>0.354876</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.370787</td>\n",
              "      <td>0.289491</td>\n",
              "      <td>0.305402</td>\n",
              "      <td>0.934616</td>\n",
              "      <td>0.015911</td>\n",
              "      <td>32.676763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.039655</td>\n",
              "      <td>0.257104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.340035</td>\n",
              "      <td>0.217448</td>\n",
              "      <td>0.300380</td>\n",
              "      <td>0.960345</td>\n",
              "      <td>0.082931</td>\n",
              "      <td>31.278309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.160633</td>\n",
              "      <td>0.350228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.446399</td>\n",
              "      <td>0.189595</td>\n",
              "      <td>0.285766</td>\n",
              "      <td>0.839367</td>\n",
              "      <td>0.096172</td>\n",
              "      <td>34.045465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377757</td>\n",
              "      <td>0.482497</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.548595</td>\n",
              "      <td>0.104740</td>\n",
              "      <td>0.170838</td>\n",
              "      <td>0.622243</td>\n",
              "      <td>0.066098</td>\n",
              "      <td>27.455162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.377437</td>\n",
              "      <td>0.477236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.546473</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.169037</td>\n",
              "      <td>0.622563</td>\n",
              "      <td>0.069237</td>\n",
              "      <td>27.151717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.027534</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.184179</td>\n",
              "      <td>-0.025282</td>\n",
              "      <td>0.156645</td>\n",
              "      <td>0.972466</td>\n",
              "      <td>0.181927</td>\n",
              "      <td>16.108055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.529180</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.552989</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.665063</td>\n",
              "      <td>0.135883</td>\n",
              "      <td>0.135451</td>\n",
              "      <td>0.470820</td>\n",
              "      <td>-0.000433</td>\n",
              "      <td>28.769094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.495465</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.584808</td>\n",
              "      <td>126500</td>\n",
              "      <td>126500</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>0.140288</td>\n",
              "      <td>0.127027</td>\n",
              "      <td>0.504535</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>25.177032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.549603</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>...</td>\n",
              "      <td>0.596958</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.123339</td>\n",
              "      <td>0.121705</td>\n",
              "      <td>0.450397</td>\n",
              "      <td>-0.001633</td>\n",
              "      <td>27.021764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.687422</td>\n",
              "      <td>0.800804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.663761</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.804012</td>\n",
              "      <td>0.113382</td>\n",
              "      <td>0.116590</td>\n",
              "      <td>0.312578</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>37.299595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.471829</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>...</td>\n",
              "      <td>0.574310</td>\n",
              "      <td>63250</td>\n",
              "      <td>126500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>0.127071</td>\n",
              "      <td>0.111923</td>\n",
              "      <td>0.528171</td>\n",
              "      <td>-0.015148</td>\n",
              "      <td>21.190624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.750413</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789872</td>\n",
              "      <td>126500</td>\n",
              "      <td>63250</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.833028</td>\n",
              "      <td>0.082615</td>\n",
              "      <td>0.080519</td>\n",
              "      <td>0.249587</td>\n",
              "      <td>-0.002096</td>\n",
              "      <td>32.260734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.733211</td>\n",
              "      <td>0.783932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.671462</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.805698</td>\n",
              "      <td>0.050721</td>\n",
              "      <td>0.072488</td>\n",
              "      <td>0.266789</td>\n",
              "      <td>0.021766</td>\n",
              "      <td>27.170422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "10                        False                      True   \n",
              "37                        False                     False   \n",
              "43                        False                     False   \n",
              "31                        False                     False   \n",
              "34                        False                     False   \n",
              "28                        False                     False   \n",
              "1                         False                      True   \n",
              "40                        False                     False   \n",
              "46                        False                     False   \n",
              "52                        False                     False   \n",
              "19                        False                      True   \n",
              "16                        False                      True   \n",
              "49                        False                     False   \n",
              "25                        False                      True   \n",
              "7                         False                      True   \n",
              "13                        False                      True   \n",
              "22                        False                      True   \n",
              "4                         False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "10                 False                  True                      True   \n",
              "37                 False                  True                      True   \n",
              "43                 False                  True                     False   \n",
              "31                  True                 False                     False   \n",
              "34                  True                 False                     False   \n",
              "28                  True                 False                      True   \n",
              "1                   True                 False                      True   \n",
              "40                 False                  True                     False   \n",
              "46                 False                 False                      True   \n",
              "52                 False                 False                     False   \n",
              "19                 False                 False                      True   \n",
              "16                 False                  True                     False   \n",
              "49                 False                 False                     False   \n",
              "25                 False                 False                     False   \n",
              "7                   True                 False                     False   \n",
              "13                 False                  True                     False   \n",
              "22                 False                 False                     False   \n",
              "4                   True                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "10                        False         False             True   \n",
              "37                        False         False             True   \n",
              "43                        False         False             True   \n",
              "31                         True         False             True   \n",
              "34                        False         False             True   \n",
              "28                        False         False             True   \n",
              "1                         False         False             True   \n",
              "40                         True         False             True   \n",
              "46                        False         False             True   \n",
              "52                        False         False             True   \n",
              "19                        False         False             True   \n",
              "16                        False         False             True   \n",
              "49                         True         False             True   \n",
              "25                        False         False             True   \n",
              "7                         False         False             True   \n",
              "13                         True         False             True   \n",
              "22                         True         False             True   \n",
              "4                          True         False             True   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "10           0.161784           0.611146  ...               0.055482   \n",
              "37           0.149899           0.537321  ...               0.000000   \n",
              "43           0.065384           0.354876  ...               0.000000   \n",
              "31           0.039655           0.257104  ...               0.000000   \n",
              "34           0.160633           0.350228  ...               0.000000   \n",
              "28           0.377757           0.482497  ...               0.000000   \n",
              "1            0.377437           0.477236  ...               0.000000   \n",
              "40           0.027534           0.002253  ...               0.000000   \n",
              "46           0.529180           0.665063  ...               0.552989   \n",
              "52           0.495465           0.635753  ...               0.584808   \n",
              "19           0.549603           0.672941  ...               0.596958   \n",
              "16           0.687422           0.800804  ...               0.663761   \n",
              "49           0.471829           0.598900  ...               0.574310   \n",
              "25           0.750413           0.833028  ...               0.789872   \n",
              "7            0.733211           0.783932  ...               0.671462   \n",
              "13           1.000000           1.000000  ...               1.000000   \n",
              "22           1.000000           1.000000  ...               1.000000   \n",
              "4            1.000000           1.000000  ...               1.000000   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "10        31625            63250                      0.50       0.633867   \n",
              "37        31625           126500                      0.25       0.551929   \n",
              "43        63250           126500                      0.50       0.370787   \n",
              "31        31625           126500                      0.25       0.340035   \n",
              "34        63250           126500                      0.50       0.446399   \n",
              "28        31625           126500                      0.25       0.548595   \n",
              "1         31625            63250                      0.50       0.546473   \n",
              "40        31625           126500                      0.25       0.184179   \n",
              "46        63250           126500                      0.50       0.665063   \n",
              "52       126500           126500                      1.00       0.635753   \n",
              "19        63250            63250                      1.00       0.672941   \n",
              "16        63250            63250                      1.00       0.804012   \n",
              "49        63250           126500                      0.50       0.598900   \n",
              "25       126500            63250                      2.00       0.833028   \n",
              "7         63250            63250                      1.00       0.805698   \n",
              "13        31625            63250                      0.50       1.000000   \n",
              "22        63250            63250                      1.00       1.000000   \n",
              "4         31625            63250                      0.50       1.000000   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "10                 0.449361                0.472083              0.838216   \n",
              "37                 0.387422                0.402030              0.850101   \n",
              "43                 0.289491                0.305402              0.934616   \n",
              "31                 0.217448                0.300380              0.960345   \n",
              "34                 0.189595                0.285766              0.839367   \n",
              "28                 0.104740                0.170838              0.622243   \n",
              "1                  0.099800                0.169037              0.622563   \n",
              "40                -0.025282                0.156645              0.972466   \n",
              "46                 0.135883                0.135451              0.470820   \n",
              "52                 0.140288                0.127027              0.504535   \n",
              "19                 0.123339                0.121705              0.450397   \n",
              "16                 0.113382                0.116590              0.312578   \n",
              "49                 0.127071                0.111923              0.528171   \n",
              "25                 0.082615                0.080519              0.249587   \n",
              "7                  0.050721                0.072488              0.266789   \n",
              "13                 0.000000                0.000000              0.000000   \n",
              "22                 0.000000                0.000000              0.000000   \n",
              "4                  0.000000                0.000000              0.000000   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "10                0.022722                  56.319967  \n",
              "37                0.014608                  47.292049  \n",
              "43                0.015911                  32.676763  \n",
              "31                0.082931                  31.278309  \n",
              "34                0.096172                  34.045465  \n",
              "28                0.066098                  27.455162  \n",
              "1                 0.069237                  27.151717  \n",
              "40                0.181927                  16.108055  \n",
              "46               -0.000433                  28.769094  \n",
              "52               -0.013261                  25.177032  \n",
              "19               -0.001633                  27.021764  \n",
              "16                0.003208                  37.299595  \n",
              "49               -0.015148                  21.190624  \n",
              "25               -0.002096                  32.260734  \n",
              "7                 0.021766                  27.170422  \n",
              "13                0.000000                        NaN  \n",
              "22                0.000000                        NaN  \n",
              "4                 0.000000                        NaN  \n",
              "\n",
              "[18 rows x 22 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[(df[\"exclude_webp\"] == False) & (df[\"exclude_nonwebp\"] == True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f87d3db5",
      "metadata": {
        "id": "f87d3db5"
      },
      "source": [
        "### Measure improvement when webp files are not present <a class=\"anchor\" id=\"no-webp\">\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9fc1ae9",
      "metadata": {
        "id": "b9fc1ae9",
        "outputId": "ca5e2301-4dc7-4c19-9ffc-990f8a2d8b86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.898661</td>\n",
              "      <td>...</td>\n",
              "      <td>0.637662</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.921899</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>0.917318</td>\n",
              "      <td>0.995419</td>\n",
              "      <td>0.023238</td>\n",
              "      <td>92.153936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.467311</td>\n",
              "      <td>0.605595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868069</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.908832</td>\n",
              "      <td>0.138284</td>\n",
              "      <td>0.441521</td>\n",
              "      <td>0.532689</td>\n",
              "      <td>0.303237</td>\n",
              "      <td>82.885331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.464884</td>\n",
              "      <td>0.609782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.773597</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.905097</td>\n",
              "      <td>0.144898</td>\n",
              "      <td>0.440214</td>\n",
              "      <td>0.535116</td>\n",
              "      <td>0.295315</td>\n",
              "      <td>82.265032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.382287</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.409335</td>\n",
              "      <td>0.381661</td>\n",
              "      <td>0.408709</td>\n",
              "      <td>0.999374</td>\n",
              "      <td>0.027048</td>\n",
              "      <td>40.896531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.265837</td>\n",
              "      <td>0.432550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.598314</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.642590</td>\n",
              "      <td>0.166712</td>\n",
              "      <td>0.376753</td>\n",
              "      <td>0.734163</td>\n",
              "      <td>0.210041</td>\n",
              "      <td>51.317359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587878</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>...</td>\n",
              "      <td>0.794393</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.925433</td>\n",
              "      <td>0.337556</td>\n",
              "      <td>0.332666</td>\n",
              "      <td>0.412122</td>\n",
              "      <td>-0.004890</td>\n",
              "      <td>80.720096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.681420</td>\n",
              "      <td>0.812995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924162</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950002</td>\n",
              "      <td>0.131575</td>\n",
              "      <td>0.268582</td>\n",
              "      <td>0.318580</td>\n",
              "      <td>0.137007</td>\n",
              "      <td>84.305973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.775933</td>\n",
              "      <td>0.824412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.929595</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.950620</td>\n",
              "      <td>0.048479</td>\n",
              "      <td>0.174687</td>\n",
              "      <td>0.224067</td>\n",
              "      <td>0.126208</td>\n",
              "      <td>77.962073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.776642</td>\n",
              "      <td>0.824534</td>\n",
              "      <td>...</td>\n",
              "      <td>0.879297</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.948914</td>\n",
              "      <td>0.047891</td>\n",
              "      <td>0.172272</td>\n",
              "      <td>0.223358</td>\n",
              "      <td>0.124381</td>\n",
              "      <td>77.128363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.836694</td>\n",
              "      <td>0.910886</td>\n",
              "      <td>...</td>\n",
              "      <td>0.959396</td>\n",
              "      <td>196912</td>\n",
              "      <td>98456</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.972387</td>\n",
              "      <td>0.074192</td>\n",
              "      <td>0.135693</td>\n",
              "      <td>0.163306</td>\n",
              "      <td>0.061501</td>\n",
              "      <td>83.091218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.734923</td>\n",
              "      <td>0.786622</td>\n",
              "      <td>...</td>\n",
              "      <td>0.805294</td>\n",
              "      <td>196912</td>\n",
              "      <td>196912</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.843251</td>\n",
              "      <td>0.051699</td>\n",
              "      <td>0.108327</td>\n",
              "      <td>0.265077</td>\n",
              "      <td>0.056628</td>\n",
              "      <td>40.866396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.888158</td>\n",
              "      <td>0.954055</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953674</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.981496</td>\n",
              "      <td>0.065897</td>\n",
              "      <td>0.093338</td>\n",
              "      <td>0.111842</td>\n",
              "      <td>0.027441</td>\n",
              "      <td>83.454913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.886298</td>\n",
              "      <td>0.947860</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953456</td>\n",
              "      <td>49228</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.979017</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>0.092719</td>\n",
              "      <td>0.113702</td>\n",
              "      <td>0.031157</td>\n",
              "      <td>81.545656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.696211</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.698988</td>\n",
              "      <td>98456</td>\n",
              "      <td>196912</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.780740</td>\n",
              "      <td>0.084529</td>\n",
              "      <td>0.076832</td>\n",
              "      <td>0.303789</td>\n",
              "      <td>-0.007697</td>\n",
              "      <td>25.291312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.941892</td>\n",
              "      <td>0.976060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.971464</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.034168</td>\n",
              "      <td>0.049327</td>\n",
              "      <td>0.058108</td>\n",
              "      <td>0.015159</td>\n",
              "      <td>84.888337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.977943</td>\n",
              "      <td>0.996875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.988729</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.998739</td>\n",
              "      <td>0.018932</td>\n",
              "      <td>0.020797</td>\n",
              "      <td>0.022057</td>\n",
              "      <td>0.001865</td>\n",
              "      <td>94.283858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.989097</td>\n",
              "      <td>0.998672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994636</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.010299</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>94.461093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.998871</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.002416</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>93.318266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "39                        False                     False   \n",
              "0                         False                      True   \n",
              "27                        False                     False   \n",
              "30                        False                     False   \n",
              "33                        False                     False   \n",
              "42                        False                     False   \n",
              "6                         False                      True   \n",
              "18                        False                      True   \n",
              "45                        False                     False   \n",
              "24                        False                      True   \n",
              "51                        False                     False   \n",
              "9                         False                      True   \n",
              "36                        False                     False   \n",
              "48                        False                     False   \n",
              "15                        False                      True   \n",
              "3                         False                      True   \n",
              "21                        False                      True   \n",
              "12                        False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "39                 False                  True                     False   \n",
              "0                   True                 False                      True   \n",
              "27                  True                 False                      True   \n",
              "30                  True                 False                     False   \n",
              "33                  True                 False                     False   \n",
              "42                 False                  True                     False   \n",
              "6                   True                 False                     False   \n",
              "18                 False                 False                      True   \n",
              "45                 False                 False                      True   \n",
              "24                 False                 False                     False   \n",
              "51                 False                 False                     False   \n",
              "9                  False                  True                      True   \n",
              "36                 False                  True                      True   \n",
              "48                 False                 False                     False   \n",
              "15                 False                  True                     False   \n",
              "3                   True                 False                     False   \n",
              "21                 False                 False                     False   \n",
              "12                 False                  True                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "39                         True          True            False   \n",
              "0                         False          True            False   \n",
              "27                        False          True            False   \n",
              "30                         True          True            False   \n",
              "33                        False          True            False   \n",
              "42                        False          True            False   \n",
              "6                         False          True            False   \n",
              "18                        False          True            False   \n",
              "45                        False          True            False   \n",
              "24                        False          True            False   \n",
              "51                        False          True            False   \n",
              "9                         False          True            False   \n",
              "36                        False          True            False   \n",
              "48                         True          True            False   \n",
              "15                        False          True            False   \n",
              "3                          True          True            False   \n",
              "21                         True          True            False   \n",
              "12                         True          True            False   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "39           0.004581           0.898661  ...               0.637662   \n",
              "0            0.467311           0.605595  ...               0.868069   \n",
              "27           0.464884           0.609782  ...               0.773597   \n",
              "30           0.000626           0.382287  ...               0.000000   \n",
              "33           0.265837           0.432550  ...               0.598314   \n",
              "42           0.587878           0.925433  ...               0.794393   \n",
              "6            0.681420           0.812995  ...               0.924162   \n",
              "18           0.775933           0.824412  ...               0.929595   \n",
              "45           0.776642           0.824534  ...               0.879297   \n",
              "24           0.836694           0.910886  ...               0.959396   \n",
              "51           0.734923           0.786622  ...               0.805294   \n",
              "9            0.888158           0.954055  ...               0.953674   \n",
              "36           0.886298           0.947860  ...               0.953456   \n",
              "48           0.696211           0.780740  ...               0.698988   \n",
              "15           0.941892           0.976060  ...               0.971464   \n",
              "3            0.977943           0.996875  ...               0.988729   \n",
              "21           0.989097           0.998672  ...               0.994636   \n",
              "12           0.997584           0.999435  ...               0.998871   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "39        49228           196912                      0.25       0.921899   \n",
              "0         49228            98456                      0.50       0.908832   \n",
              "27        49228           196912                      0.25       0.905097   \n",
              "30        49228           196912                      0.25       0.409335   \n",
              "33        98456           196912                      0.50       0.642590   \n",
              "42        98456           196912                      0.50       0.925433   \n",
              "6         98456            98456                      1.00       0.950002   \n",
              "18        98456            98456                      1.00       0.950620   \n",
              "45        98456           196912                      0.50       0.948914   \n",
              "24       196912            98456                      2.00       0.972387   \n",
              "51       196912           196912                      1.00       0.843251   \n",
              "9         49228            98456                      0.50       0.981496   \n",
              "36        49228           196912                      0.25       0.979017   \n",
              "48        98456           196912                      0.50       0.780740   \n",
              "15        98456            98456                      1.00       0.991219   \n",
              "3         49228            98456                      0.50       0.998739   \n",
              "21        98456            98456                      1.00       0.999396   \n",
              "12        49228            98456                      0.50       0.999839   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "39                 0.894079                0.917318              0.995419   \n",
              "0                  0.138284                0.441521              0.532689   \n",
              "27                 0.144898                0.440214              0.535116   \n",
              "30                 0.381661                0.408709              0.999374   \n",
              "33                 0.166712                0.376753              0.734163   \n",
              "42                 0.337556                0.332666              0.412122   \n",
              "6                  0.131575                0.268582              0.318580   \n",
              "18                 0.048479                0.174687              0.224067   \n",
              "45                 0.047891                0.172272              0.223358   \n",
              "24                 0.074192                0.135693              0.163306   \n",
              "51                 0.051699                0.108327              0.265077   \n",
              "9                  0.065897                0.093338              0.111842   \n",
              "36                 0.061563                0.092719              0.113702   \n",
              "48                 0.084529                0.076832              0.303789   \n",
              "15                 0.034168                0.049327              0.058108   \n",
              "3                  0.018932                0.020797              0.022057   \n",
              "21                 0.009575                0.010299              0.010903   \n",
              "12                 0.001851                0.002255              0.002416   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "39                0.023238                  92.153936  \n",
              "0                 0.303237                  82.885331  \n",
              "27                0.295315                  82.265032  \n",
              "30                0.027048                  40.896531  \n",
              "33                0.210041                  51.317359  \n",
              "42               -0.004890                  80.720096  \n",
              "6                 0.137007                  84.305973  \n",
              "18                0.126208                  77.962073  \n",
              "45                0.124381                  77.128363  \n",
              "24                0.061501                  83.091218  \n",
              "51                0.056628                  40.866396  \n",
              "9                 0.027441                  83.454913  \n",
              "36                0.031157                  81.545656  \n",
              "48               -0.007697                  25.291312  \n",
              "15                0.015159                  84.888337  \n",
              "3                 0.001865                  94.283858  \n",
              "21                0.000724                  94.461093  \n",
              "12                0.000403                  93.318266  \n",
              "\n",
              "[18 rows x 22 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[(df[\"exclude_webp\"] == True) & (df[\"exclude_nonwebp\"] == False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c110718b",
      "metadata": {
        "id": "c110718b"
      },
      "source": [
        "### Measure improvement for balanced datasets <a class=\"anchor\" id=\"balanced-dataset\">\n",
        "\n",
        "Most of our dataset selections are not balanced, and we didn't do anything to mitigate\n",
        "unablanced datasets. This is because we are measuring the baseline and improvement on the\n",
        "same dataset.\n",
        "    \n",
        "However, we will select those instances where the datasets were balanced to see if the\n",
        "improvement is still significant in these instances.\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3c27a98",
      "metadata": {
        "id": "c3c27a98",
        "outputId": "36e7f67d-7ba9-4bd6-b16a-8bffba3a1375"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.681420</td>\n",
              "      <td>0.812995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924162</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950002</td>\n",
              "      <td>0.131575</td>\n",
              "      <td>0.268582</td>\n",
              "      <td>0.318580</td>\n",
              "      <td>0.137007</td>\n",
              "      <td>84.305973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.638073</td>\n",
              "      <td>0.776373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.790066</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.867715</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>0.229642</td>\n",
              "      <td>0.361927</td>\n",
              "      <td>0.091342</td>\n",
              "      <td>63.449847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.775933</td>\n",
              "      <td>0.824412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.929595</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950620</td>\n",
              "      <td>0.048479</td>\n",
              "      <td>0.174687</td>\n",
              "      <td>0.224067</td>\n",
              "      <td>0.126208</td>\n",
              "      <td>77.962073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.495465</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.584808</td>\n",
              "      <td>126500</td>\n",
              "      <td>126500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635753</td>\n",
              "      <td>0.140288</td>\n",
              "      <td>0.127027</td>\n",
              "      <td>0.504535</td>\n",
              "      <td>-0.013261</td>\n",
              "      <td>25.177032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.549603</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>...</td>\n",
              "      <td>0.596958</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.672941</td>\n",
              "      <td>0.123339</td>\n",
              "      <td>0.121705</td>\n",
              "      <td>0.450397</td>\n",
              "      <td>-0.001633</td>\n",
              "      <td>27.021764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.687422</td>\n",
              "      <td>0.800804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.663761</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.804012</td>\n",
              "      <td>0.113382</td>\n",
              "      <td>0.116590</td>\n",
              "      <td>0.312578</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>37.299595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.734923</td>\n",
              "      <td>0.786622</td>\n",
              "      <td>...</td>\n",
              "      <td>0.805294</td>\n",
              "      <td>196912</td>\n",
              "      <td>196912</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.843251</td>\n",
              "      <td>0.051699</td>\n",
              "      <td>0.108327</td>\n",
              "      <td>0.265077</td>\n",
              "      <td>0.056628</td>\n",
              "      <td>40.866396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.727722</td>\n",
              "      <td>0.724755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.783678</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810304</td>\n",
              "      <td>-0.002966</td>\n",
              "      <td>0.082582</td>\n",
              "      <td>0.272278</td>\n",
              "      <td>0.085548</td>\n",
              "      <td>30.330069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.733211</td>\n",
              "      <td>0.783932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.671462</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.805698</td>\n",
              "      <td>0.050721</td>\n",
              "      <td>0.072488</td>\n",
              "      <td>0.266789</td>\n",
              "      <td>0.021766</td>\n",
              "      <td>27.170422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.941892</td>\n",
              "      <td>0.976060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.971464</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.034168</td>\n",
              "      <td>0.049327</td>\n",
              "      <td>0.058108</td>\n",
              "      <td>0.015159</td>\n",
              "      <td>84.888337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.682685</td>\n",
              "      <td>0.687901</td>\n",
              "      <td>...</td>\n",
              "      <td>0.718802</td>\n",
              "      <td>323412</td>\n",
              "      <td>323412</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728202</td>\n",
              "      <td>0.005216</td>\n",
              "      <td>0.045516</td>\n",
              "      <td>0.317315</td>\n",
              "      <td>0.040301</td>\n",
              "      <td>14.344259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.842512</td>\n",
              "      <td>0.856841</td>\n",
              "      <td>...</td>\n",
              "      <td>0.803801</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.869639</td>\n",
              "      <td>0.014329</td>\n",
              "      <td>0.027127</td>\n",
              "      <td>0.157488</td>\n",
              "      <td>0.012798</td>\n",
              "      <td>17.224592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.989097</td>\n",
              "      <td>0.998672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994636</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.010299</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>94.461093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.992795</td>\n",
              "      <td>0.998939</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996928</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999555</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>93.829816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "6                         False                      True   \n",
              "8                         False                      True   \n",
              "18                        False                      True   \n",
              "52                        False                     False   \n",
              "19                        False                      True   \n",
              "16                        False                      True   \n",
              "51                        False                     False   \n",
              "20                        False                      True   \n",
              "7                         False                      True   \n",
              "15                        False                      True   \n",
              "53                        False                     False   \n",
              "17                        False                      True   \n",
              "21                        False                      True   \n",
              "23                        False                      True   \n",
              "22                        False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "6                   True                 False                     False   \n",
              "8                   True                 False                     False   \n",
              "18                 False                 False                      True   \n",
              "52                 False                 False                     False   \n",
              "19                 False                 False                      True   \n",
              "16                 False                  True                     False   \n",
              "51                 False                 False                     False   \n",
              "20                 False                 False                      True   \n",
              "7                   True                 False                     False   \n",
              "15                 False                  True                     False   \n",
              "53                 False                 False                     False   \n",
              "17                 False                  True                     False   \n",
              "21                 False                 False                     False   \n",
              "23                 False                 False                     False   \n",
              "22                 False                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "6                         False          True            False   \n",
              "8                         False         False            False   \n",
              "18                        False          True            False   \n",
              "52                        False         False             True   \n",
              "19                        False         False             True   \n",
              "16                        False         False             True   \n",
              "51                        False          True            False   \n",
              "20                        False         False            False   \n",
              "7                         False         False             True   \n",
              "15                        False          True            False   \n",
              "53                        False         False            False   \n",
              "17                        False         False            False   \n",
              "21                         True          True            False   \n",
              "23                         True         False            False   \n",
              "22                         True         False             True   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "6            0.681420           0.812995  ...               0.924162   \n",
              "8            0.638073           0.776373  ...               0.790066   \n",
              "18           0.775933           0.824412  ...               0.929595   \n",
              "52           0.495465           0.635753  ...               0.584808   \n",
              "19           0.549603           0.672941  ...               0.596958   \n",
              "16           0.687422           0.800804  ...               0.663761   \n",
              "51           0.734923           0.786622  ...               0.805294   \n",
              "20           0.727722           0.724755  ...               0.783678   \n",
              "7            0.733211           0.783932  ...               0.671462   \n",
              "15           0.941892           0.976060  ...               0.971464   \n",
              "53           0.682685           0.687901  ...               0.718802   \n",
              "17           0.842512           0.856841  ...               0.803801   \n",
              "21           0.989097           0.998672  ...               0.994636   \n",
              "23           0.992795           0.998939  ...               0.996928   \n",
              "22           1.000000           1.000000  ...               1.000000   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "6         98456            98456                       1.0       0.950002   \n",
              "8        161706           161706                       1.0       0.867715   \n",
              "18        98456            98456                       1.0       0.950620   \n",
              "52       126500           126500                       1.0       0.635753   \n",
              "19        63250            63250                       1.0       0.672941   \n",
              "16        63250            63250                       1.0       0.804012   \n",
              "51       196912           196912                       1.0       0.843251   \n",
              "20       161706           161706                       1.0       0.810304   \n",
              "7         63250            63250                       1.0       0.805698   \n",
              "15        98456            98456                       1.0       0.991219   \n",
              "53       323412           323412                       1.0       0.728202   \n",
              "17       161706           161706                       1.0       0.869639   \n",
              "21        98456            98456                       1.0       0.999396   \n",
              "23       161706           161706                       1.0       0.999555   \n",
              "22        63250            63250                       1.0       1.000000   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "6                  0.131575                0.268582              0.318580   \n",
              "8                  0.138300                0.229642              0.361927   \n",
              "18                 0.048479                0.174687              0.224067   \n",
              "52                 0.140288                0.127027              0.504535   \n",
              "19                 0.123339                0.121705              0.450397   \n",
              "16                 0.113382                0.116590              0.312578   \n",
              "51                 0.051699                0.108327              0.265077   \n",
              "20                -0.002966                0.082582              0.272278   \n",
              "7                  0.050721                0.072488              0.266789   \n",
              "15                 0.034168                0.049327              0.058108   \n",
              "53                 0.005216                0.045516              0.317315   \n",
              "17                 0.014329                0.027127              0.157488   \n",
              "21                 0.009575                0.010299              0.010903   \n",
              "23                 0.006143                0.006760              0.007205   \n",
              "22                 0.000000                0.000000              0.000000   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "6                 0.137007                  84.305973  \n",
              "8                 0.091342                  63.449847  \n",
              "18                0.126208                  77.962073  \n",
              "52               -0.013261                  25.177032  \n",
              "19               -0.001633                  27.021764  \n",
              "16                0.003208                  37.299595  \n",
              "51                0.056628                  40.866396  \n",
              "20                0.085548                  30.330069  \n",
              "7                 0.021766                  27.170422  \n",
              "15                0.015159                  84.888337  \n",
              "53                0.040301                  14.344259  \n",
              "17                0.012798                  17.224592  \n",
              "21                0.000724                  94.461093  \n",
              "23                0.000617                  93.829816  \n",
              "22                0.000000                        NaN  \n",
              "\n",
              "[15 rows x 22 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df[df[\"ratio_encrypt_nonencrypt\"] == 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7ba0ff",
      "metadata": {
        "id": "db7ba0ff"
      },
      "source": [
        "### Measure the improvement when all files are used <a class=\"anchor\" id=\"full-dataset\">\n",
        "\n",
        "In most of our dataset selections, we excluded some data points based on our criteria.\n",
        "\n",
        "In this, we measure the improvement when we use all data points\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f3cbec",
      "metadata": {
        "id": "38f3cbec",
        "outputId": "b26ee05c-5b75-4bdd-b47c-87ab89c5e7ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.682685</td>\n",
              "      <td>0.687901</td>\n",
              "      <td>...</td>\n",
              "      <td>0.718802</td>\n",
              "      <td>323412</td>\n",
              "      <td>323412</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.728202</td>\n",
              "      <td>0.005216</td>\n",
              "      <td>0.045516</td>\n",
              "      <td>0.317315</td>\n",
              "      <td>0.040301</td>\n",
              "      <td>14.344259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "53                        False                     False   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "53                 False                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "53                        False         False            False   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "53           0.682685           0.687901  ...               0.718802   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "53       323412           323412                       1.0       0.728202   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "53                 0.005216                0.045516              0.317315   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "53                0.040301                  14.344259  \n",
              "\n",
              "[1 rows x 22 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Measure everything for the full dataset\n",
        "df2 = df\n",
        "for colname in df2.columns:\n",
        "    if \"exclude\" in colname:\n",
        "        df2 = df2[df2[colname] == False]\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a187044",
      "metadata": {
        "id": "6a187044"
      },
      "outputs": [],
      "source": [
        "df.to_parquet(\"../comparison_logistic_regression_final.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204adc5a",
      "metadata": {
        "id": "204adc5a"
      },
      "source": [
        "### Focus on items where the base metrics performed well <a class=\"anchor\" id=\"focus-greater-90\">\n",
        "\n",
        "We see that in all cases, plaintext non-base 32 only is selected. Also we\n",
        "see that for encrypted, only base32 is selected and non-base32 excluded.\n",
        "    \n",
        "Fundamentally, what this is measuring is when the plaintext has all files\n",
        "but all encrypted content is base-32 encoded.\n",
        "\n",
        "Typically, base-32 encoding will lead to a reduction of entropy, in many cases\n",
        "much less than the original text, and this is what it is measuring.\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac03930c",
      "metadata": {
        "id": "ac03930c",
        "outputId": "bdee4ecb-6fa4-46eb-d79a-5fdff14c1a93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exclude_plaintext_nonbase32</th>\n",
              "      <th>exclude_plaintext_base32</th>\n",
              "      <th>exclude_encrypted_v1</th>\n",
              "      <th>exclude_encrypted_v2</th>\n",
              "      <th>exclude_encrypted_base32</th>\n",
              "      <th>exclude_encrypted_nonbase32</th>\n",
              "      <th>exclude_webp</th>\n",
              "      <th>exclude_nonwebp</th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>...</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>n_encrypted</th>\n",
              "      <th>n_non_encrypted</th>\n",
              "      <th>ratio_encrypt_nonencrypt</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "      <th>room_for_improvement</th>\n",
              "      <th>fourier_minus_advanced</th>\n",
              "      <th>percentage_of_room_filled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.941892</td>\n",
              "      <td>0.976060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.971464</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.991219</td>\n",
              "      <td>0.034168</td>\n",
              "      <td>0.049327</td>\n",
              "      <td>0.058108</td>\n",
              "      <td>0.015159</td>\n",
              "      <td>84.888337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.977943</td>\n",
              "      <td>0.996875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.988729</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.998739</td>\n",
              "      <td>0.018932</td>\n",
              "      <td>0.020797</td>\n",
              "      <td>0.022057</td>\n",
              "      <td>0.001865</td>\n",
              "      <td>94.283858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.985924</td>\n",
              "      <td>0.997995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993397</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.999207</td>\n",
              "      <td>0.012072</td>\n",
              "      <td>0.013283</td>\n",
              "      <td>0.014076</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>94.368169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.989097</td>\n",
              "      <td>0.998672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994636</td>\n",
              "      <td>98456</td>\n",
              "      <td>98456</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999396</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.010299</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>94.461093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.992795</td>\n",
              "      <td>0.998939</td>\n",
              "      <td>...</td>\n",
              "      <td>0.996928</td>\n",
              "      <td>161706</td>\n",
              "      <td>161706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999555</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>93.829816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.999435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.998871</td>\n",
              "      <td>49228</td>\n",
              "      <td>98456</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.999839</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.002416</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>93.318266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.998388</td>\n",
              "      <td>0.999584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999169</td>\n",
              "      <td>80853</td>\n",
              "      <td>161706</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.999853</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>90.895747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>63250</td>\n",
              "      <td>63250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31625</td>\n",
              "      <td>63250</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    exclude_plaintext_nonbase32  exclude_plaintext_base32  \\\n",
              "15                        False                      True   \n",
              "3                         False                      True   \n",
              "5                         False                      True   \n",
              "21                        False                      True   \n",
              "23                        False                      True   \n",
              "12                        False                      True   \n",
              "14                        False                      True   \n",
              "13                        False                      True   \n",
              "22                        False                      True   \n",
              "4                         False                      True   \n",
              "\n",
              "    exclude_encrypted_v1  exclude_encrypted_v2  exclude_encrypted_base32  \\\n",
              "15                 False                  True                     False   \n",
              "3                   True                 False                     False   \n",
              "5                   True                 False                     False   \n",
              "21                 False                 False                     False   \n",
              "23                 False                 False                     False   \n",
              "12                 False                  True                     False   \n",
              "14                 False                  True                     False   \n",
              "13                 False                  True                     False   \n",
              "22                 False                 False                     False   \n",
              "4                   True                 False                     False   \n",
              "\n",
              "    exclude_encrypted_nonbase32  exclude_webp  exclude_nonwebp  \\\n",
              "15                        False          True            False   \n",
              "3                          True          True            False   \n",
              "5                          True         False            False   \n",
              "21                         True          True            False   \n",
              "23                         True         False            False   \n",
              "12                         True          True            False   \n",
              "14                         True         False            False   \n",
              "13                         True         False             True   \n",
              "22                         True         False             True   \n",
              "4                          True         False             True   \n",
              "\n",
              "    baseline-f1_score  advanced-f1_score  ...  fourier-only-f1_score  \\\n",
              "15           0.941892           0.976060  ...               0.971464   \n",
              "3            0.977943           0.996875  ...               0.988729   \n",
              "5            0.985924           0.997995  ...               0.993397   \n",
              "21           0.989097           0.998672  ...               0.994636   \n",
              "23           0.992795           0.998939  ...               0.996928   \n",
              "12           0.997584           0.999435  ...               0.998871   \n",
              "14           0.998388           0.999584  ...               0.999169   \n",
              "13           1.000000           1.000000  ...               1.000000   \n",
              "22           1.000000           1.000000  ...               1.000000   \n",
              "4            1.000000           1.000000  ...               1.000000   \n",
              "\n",
              "    n_encrypted  n_non_encrypted  ratio_encrypt_nonencrypt  best_f1_score  \\\n",
              "15        98456            98456                       1.0       0.991219   \n",
              "3         49228            98456                       0.5       0.998739   \n",
              "5         80853           161706                       0.5       0.999207   \n",
              "21        98456            98456                       1.0       0.999396   \n",
              "23       161706           161706                       1.0       0.999555   \n",
              "12        49228            98456                       0.5       0.999839   \n",
              "14        80853           161706                       0.5       0.999853   \n",
              "13        31625            63250                       0.5       1.000000   \n",
              "22        63250            63250                       1.0       1.000000   \n",
              "4         31625            63250                       0.5       1.000000   \n",
              "\n",
              "    improvement_in_advanced  improvement_in_fourier  room_for_improvement  \\\n",
              "15                 0.034168                0.049327              0.058108   \n",
              "3                  0.018932                0.020797              0.022057   \n",
              "5                  0.012072                0.013283              0.014076   \n",
              "21                 0.009575                0.010299              0.010903   \n",
              "23                 0.006143                0.006760              0.007205   \n",
              "12                 0.001851                0.002255              0.002416   \n",
              "14                 0.001196                0.001465              0.001612   \n",
              "13                 0.000000                0.000000              0.000000   \n",
              "22                 0.000000                0.000000              0.000000   \n",
              "4                  0.000000                0.000000              0.000000   \n",
              "\n",
              "    fourier_minus_advanced  percentage_of_room_filled  \n",
              "15                0.015159                  84.888337  \n",
              "3                 0.001865                  94.283858  \n",
              "5                 0.001212                  94.368169  \n",
              "21                0.000724                  94.461093  \n",
              "23                0.000617                  93.829816  \n",
              "12                0.000403                  93.318266  \n",
              "14                0.000269                  90.895747  \n",
              "13                0.000000                        NaN  \n",
              "22                0.000000                        NaN  \n",
              "4                 0.000000                        NaN  \n",
              "\n",
              "[10 rows x 22 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df[\"baseline-f1_score\"] > 0.9]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edbe55b8",
      "metadata": {
        "id": "edbe55b8"
      },
      "source": [
        "### Correlation of data set and performance <a class=\"anchor\" id=\"corr-heatmap\">\n",
        "    \n",
        "This gives more idea on how data-set selection affects performance.\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86fd4d7",
      "metadata": {
        "id": "e86fd4d7",
        "outputId": "a7f566a6-b412-4813-9a0f-0f13cef023e7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "sns.heatmap(df.astype(float).corr(), cmap='coolwarm')\n",
        "# print(df[df[\"baseline-f1_score\"] > 0.9].astype(float))\n",
        "_ = plt.xticks(rotation=80) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c15673",
      "metadata": {
        "id": "f2c15673",
        "outputId": "0bddae55-4bdd-4f9e-d152-19a9164a0a13"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df1 = df[[\"exclude_encrypted_base32\", \"exclude_encrypted_v2\", \"exclude_webp\", \"baseline-f1_score\", \"advanced-f1_score\", \"fourier-f1_score\"]]\n",
        "sns.heatmap(df1.astype(float).corr(), cmap='coolwarm')\n",
        "_ = plt.xticks(rotation=80) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5198fd5",
      "metadata": {
        "id": "f5198fd5"
      },
      "source": [
        "### Average out all the metrics <a class=\"anchor\" id=\"mean-fscores\">\n",
        "\n",
        "To conclude we report the average of the f1-scores and the improvements with all datasets\n",
        "    \n",
        "[top](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d231ca",
      "metadata": {
        "id": "74d231ca",
        "outputId": "d6561b9e-4862-4e11-8071-0a1b7c6460f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "baseline-f1_score          0.577340\n",
              "advanced-f1_score          0.710232\n",
              "advanced-only-f1_score     0.700871\n",
              "fourier-f1_score           0.766661\n",
              "fourier-only-f1_score      0.620752\n",
              "best_f1_score              0.767940\n",
              "improvement_in_advanced    0.132891\n",
              "improvement_in_fourier     0.189320\n",
              "dtype: float64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[[c for c in df.columns if (\"score\" in c or \"improvement\" in c) and \"room\" not in c]].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308e6fce",
      "metadata": {
        "id": "308e6fce",
        "outputId": "2eb673aa-c4df-4fa5-dac3-1975545ca64d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>advanced-only-f1_score</th>\n",
              "      <th>fourier-f1_score</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.577340</td>\n",
              "      <td>0.710232</td>\n",
              "      <td>0.700871</td>\n",
              "      <td>0.766661</td>\n",
              "      <td>0.620752</td>\n",
              "      <td>0.767940</td>\n",
              "      <td>0.132891</td>\n",
              "      <td>0.189320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.330152</td>\n",
              "      <td>0.242409</td>\n",
              "      <td>0.249414</td>\n",
              "      <td>0.221063</td>\n",
              "      <td>0.356735</td>\n",
              "      <td>0.220068</td>\n",
              "      <td>0.173406</td>\n",
              "      <td>0.194050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121932</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>-0.025282</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.331869</td>\n",
              "      <td>0.600574</td>\n",
              "      <td>0.562187</td>\n",
              "      <td>0.648100</td>\n",
              "      <td>0.497884</td>\n",
              "      <td>0.648208</td>\n",
              "      <td>0.018926</td>\n",
              "      <td>0.046469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.682053</td>\n",
              "      <td>0.732800</td>\n",
              "      <td>0.715985</td>\n",
              "      <td>0.808001</td>\n",
              "      <td>0.708895</td>\n",
              "      <td>0.808001</td>\n",
              "      <td>0.083572</td>\n",
              "      <td>0.121819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.831554</td>\n",
              "      <td>0.907830</td>\n",
              "      <td>0.908704</td>\n",
              "      <td>0.950466</td>\n",
              "      <td>0.928237</td>\n",
              "      <td>0.950466</td>\n",
              "      <td>0.161259</td>\n",
              "      <td>0.296726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>0.917318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       baseline-f1_score  advanced-f1_score  advanced-only-f1_score  \\\n",
              "count          54.000000          54.000000               54.000000   \n",
              "mean            0.577340           0.710232                0.700871   \n",
              "std             0.330152           0.242409                0.249414   \n",
              "min             0.000000           0.002253                0.000000   \n",
              "25%             0.331869           0.600574                0.562187   \n",
              "50%             0.682053           0.732800                0.715985   \n",
              "75%             0.831554           0.907830                0.908704   \n",
              "max             1.000000           1.000000                1.000000   \n",
              "\n",
              "       fourier-f1_score  fourier-only-f1_score  best_f1_score  \\\n",
              "count         54.000000              54.000000      54.000000   \n",
              "mean           0.766661               0.620752       0.767940   \n",
              "std            0.221063               0.356735       0.220068   \n",
              "min            0.121932               0.000000       0.132504   \n",
              "25%            0.648100               0.497884       0.648208   \n",
              "50%            0.808001               0.708895       0.808001   \n",
              "75%            0.950466               0.928237       0.950466   \n",
              "max            1.000000               1.000000       1.000000   \n",
              "\n",
              "       improvement_in_advanced  improvement_in_fourier  \n",
              "count                54.000000               54.000000  \n",
              "mean                  0.132891                0.189320  \n",
              "std                   0.173406                0.194050  \n",
              "min                  -0.025282                0.000000  \n",
              "25%                   0.018926                0.046469  \n",
              "50%                   0.083572                0.121819  \n",
              "75%                   0.161259                0.296726  \n",
              "max                   0.894079                0.917318  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[[c for c in df.columns if (\"score\" in c or \"improvement\" in c) and \"room\" not in c]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b185923",
      "metadata": {
        "id": "2b185923",
        "outputId": "d7001e92-8115-44c3-f005-5e68402b2b80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline-f1_score</th>\n",
              "      <th>advanced-only-f1_score</th>\n",
              "      <th>fourier-only-f1_score</th>\n",
              "      <th>advanced-f1_score</th>\n",
              "      <th>fourier-f1_score</th>\n",
              "      <th>best_f1_score</th>\n",
              "      <th>improvement_in_advanced</th>\n",
              "      <th>improvement_in_fourier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.577340</td>\n",
              "      <td>0.700871</td>\n",
              "      <td>0.620752</td>\n",
              "      <td>0.710232</td>\n",
              "      <td>0.766661</td>\n",
              "      <td>0.767940</td>\n",
              "      <td>0.132891</td>\n",
              "      <td>0.189320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.330152</td>\n",
              "      <td>0.249414</td>\n",
              "      <td>0.356735</td>\n",
              "      <td>0.242409</td>\n",
              "      <td>0.221063</td>\n",
              "      <td>0.220068</td>\n",
              "      <td>0.173406</td>\n",
              "      <td>0.194050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>0.121932</td>\n",
              "      <td>0.132504</td>\n",
              "      <td>-0.025282</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.331869</td>\n",
              "      <td>0.562187</td>\n",
              "      <td>0.497884</td>\n",
              "      <td>0.600574</td>\n",
              "      <td>0.648100</td>\n",
              "      <td>0.648208</td>\n",
              "      <td>0.018926</td>\n",
              "      <td>0.046469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.682053</td>\n",
              "      <td>0.715985</td>\n",
              "      <td>0.708895</td>\n",
              "      <td>0.732800</td>\n",
              "      <td>0.808001</td>\n",
              "      <td>0.808001</td>\n",
              "      <td>0.083572</td>\n",
              "      <td>0.121819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.831554</td>\n",
              "      <td>0.908704</td>\n",
              "      <td>0.928237</td>\n",
              "      <td>0.907830</td>\n",
              "      <td>0.950466</td>\n",
              "      <td>0.950466</td>\n",
              "      <td>0.161259</td>\n",
              "      <td>0.296726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.894079</td>\n",
              "      <td>0.917318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       baseline-f1_score  advanced-only-f1_score  fourier-only-f1_score  \\\n",
              "count          54.000000               54.000000              54.000000   \n",
              "mean            0.577340                0.700871               0.620752   \n",
              "std             0.330152                0.249414               0.356735   \n",
              "min             0.000000                0.000000               0.000000   \n",
              "25%             0.331869                0.562187               0.497884   \n",
              "50%             0.682053                0.715985               0.708895   \n",
              "75%             0.831554                0.908704               0.928237   \n",
              "max             1.000000                1.000000               1.000000   \n",
              "\n",
              "       advanced-f1_score  fourier-f1_score  best_f1_score  \\\n",
              "count          54.000000         54.000000      54.000000   \n",
              "mean            0.710232          0.766661       0.767940   \n",
              "std             0.242409          0.221063       0.220068   \n",
              "min             0.002253          0.121932       0.132504   \n",
              "25%             0.600574          0.648100       0.648208   \n",
              "50%             0.732800          0.808001       0.808001   \n",
              "75%             0.907830          0.950466       0.950466   \n",
              "max             1.000000          1.000000       1.000000   \n",
              "\n",
              "       improvement_in_advanced  improvement_in_fourier  \n",
              "count                54.000000               54.000000  \n",
              "mean                  0.132891                0.189320  \n",
              "std                   0.173406                0.194050  \n",
              "min                  -0.025282                0.000000  \n",
              "25%                   0.018926                0.046469  \n",
              "50%                   0.083572                0.121819  \n",
              "75%                   0.161259                0.296726  \n",
              "max                   0.894079                0.917318  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = df[[c for c in df.columns if (\"score\" in c or \"improvement\" in c) and \"room\" not in c]]\n",
        "columns = [\"baseline-f1_score\"]\n",
        "columns += [c for c in df1.columns if \"only\" in c]\n",
        "columns += [c for c in df1.columns if \"only\" not in c and \"baseline-f1_score\" != c]\n",
        "df1[columns].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40399cb",
      "metadata": {
        "id": "c40399cb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "COLABTEST_iteration_2.1_LR_compare_base32_logistic_regression.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}