{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea20739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f716a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCRYPTED_DIRECTORY = \"data/govdocs_encrypted\"\n",
    "PLAINTEXT_DIRECTORY = \"data/govdocs_plaintext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1205a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_25304/2908337352.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_plaintext[\"is_encrypted\"] = 0\n",
      "/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_25304/2908337352.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_encrypted[\"is_encrypted\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only webp:  (160507, 528)\n",
      "greater than 4096:  (160507, 528)\n"
     ]
    }
   ],
   "source": [
    "def load_data(directory):\n",
    "    dataframes = list()\n",
    "    for f in glob.glob(f\"{directory}/**.csv.gz\"):\n",
    "        df = pd.read_csv(f)\n",
    "        dataframes.append(df)\n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "df_plaintext = load_data(PLAINTEXT_DIRECTORY)\n",
    "df_plaintext[\"is_encrypted\"] = 0\n",
    "df_encrypted = load_data(ENCRYPTED_DIRECTORY)\n",
    "df_encrypted[\"is_encrypted\"] = 1\n",
    "\n",
    "master_df = pd.concat([df_plaintext, df_encrypted])\n",
    "\n",
    "# Filter out only webp\n",
    "# master_df = master_df[master_df['extended.extension'] != '.webp']\n",
    "print(\"only webp: \", master_df.shape)\n",
    "\n",
    "# Filter out files which are larger than 4k\n",
    "#master_df = master_df[master_df['baseline.filesize'] > 4096]\n",
    "print(\"greater than 4096: \", master_df.shape)\n",
    "\n",
    "# Shuffle\n",
    "master_df = master_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fill Nan with 0\n",
    "master_df['baseline.chisquare_end'] = master_df['baseline.chisquare_end'].fillna(0.0)\n",
    "master_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5952bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if \"size\" not in c.lower()]]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression())]\n",
    "estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "print(precision, recall, fscore, support)\n",
    "print(f\"F1 = {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = master_df[X_train.isna().any(axis=1)]\n",
    "#print(df1)\n",
    "#print(X_train.describe().T)\n",
    "print(rfc.feature_importances_)\n",
    "plt.barh(X_train.columns, rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee881566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
