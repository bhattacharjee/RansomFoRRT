{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea20739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f716a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCRYPTED_DIRECTORY = \"data/govdocs_encrypted\"\n",
    "PLAINTEXT_DIRECTORY = \"data/govdocs_plaintext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1205a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_18157/2908337352.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_plaintext[\"is_encrypted\"] = 0\n",
      "/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_18157/2908337352.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_encrypted[\"is_encrypted\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only webp:  (160507, 528)\n",
      "greater than 4096:  (160507, 528)\n"
     ]
    }
   ],
   "source": [
    "def load_data(directory):\n",
    "    dataframes = list()\n",
    "    for f in glob.glob(f\"{directory}/**.csv.gz\"):\n",
    "        df = pd.read_csv(f)\n",
    "        dataframes.append(df)\n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "df_plaintext = load_data(PLAINTEXT_DIRECTORY)\n",
    "df_plaintext[\"is_encrypted\"] = 0\n",
    "df_encrypted = load_data(ENCRYPTED_DIRECTORY)\n",
    "df_encrypted[\"is_encrypted\"] = 1\n",
    "\n",
    "master_df = pd.concat([df_plaintext, df_encrypted])\n",
    "\n",
    "# Filter out only webp\n",
    "# master_df = master_df[master_df['extended.extension'] != '.webp']\n",
    "print(\"only webp: \", master_df.shape)\n",
    "\n",
    "# Filter out files which are larger than 4k\n",
    "#master_df = master_df[master_df['baseline.filesize'] > 4096]\n",
    "print(\"greater than 4096: \", master_df.shape)\n",
    "\n",
    "# Shuffle\n",
    "master_df = master_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fill Nan with 0\n",
    "master_df['baseline.chisquare_end'] = master_df['baseline.chisquare_end'].fillna(0.0)\n",
    "master_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927e73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.6894083969465649\n",
      "Recall    : 0.775006704210244\n",
      "Accuracy  : 0.7138083143964711\n",
      "F1-score  : 0.7297058452215629\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10, max_iter=1000))]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json = {\n",
    "    \"Extremities_Measured_Separately\": [],\n",
    "    \"Algorithm\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1\": []\n",
    "}\n",
    "\n",
    "df_json[\"Extremities_Measured_Separately\"].append(\"NO\")\n",
    "df_json[\"Algorithm\"].append(\"Logistic Regression\")\n",
    "df_json[\"Accuracy\"].append(accuracy)\n",
    "df_json[\"Precision\"].append(precision)\n",
    "df_json[\"Recall\"].append(recall)\n",
    "df_json[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8307d-be7e-4159-83a4-e0d379746d63",
   "metadata": {},
   "source": [
    "## Now try the same thing with extremity measurements separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f1da3e-1ef2-445b-af14-7984fbed9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7941059865204176\n",
      "Recall    : 0.8057119871279164\n",
      "Accuracy  : 0.7990241946263869\n",
      "F1-score  : 0.7998668885191348\n"
     ]
    }
   ],
   "source": [
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "# X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "# X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10,  max_iter=1000))]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "\n",
    "df_json[\"Extremities_Measured_Separately\"].append(\"YES\")\n",
    "df_json[\"Algorithm\"].append(\"Logistic Regression\")\n",
    "df_json[\"Accuracy\"].append(accuracy)\n",
    "df_json[\"Precision\"].append(precision)\n",
    "df_json[\"Recall\"].append(recall)\n",
    "df_json[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5609897-29be-4ae1-a08f-1272222a3960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7000973709834469\n",
      "Recall    : 0.7712523464735854\n",
      "Accuracy  : 0.7212939446598048\n",
      "F1-score  : 0.7339543192548168\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json[\"Extremities_Measured_Separately\"].append(\"NO\")\n",
    "df_json[\"Algorithm\"].append(\"Random Forest\")\n",
    "df_json[\"Accuracy\"].append(accuracy)\n",
    "df_json[\"Precision\"].append(precision)\n",
    "df_json[\"Recall\"].append(recall)\n",
    "df_json[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea42049b-2f85-4d92-a7f2-95a1ecb6c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.8209750102417043\n",
      "Recall    : 0.8061142397425584\n",
      "Accuracy  : 0.8157331907498997\n",
      "F1-score  : 0.8134767607063123\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "#X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "#X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json[\"Extremities_Measured_Separately\"].append(\"YES\")\n",
    "df_json[\"Algorithm\"].append(\"Random Forest\")\n",
    "df_json[\"Accuracy\"].append(accuracy)\n",
    "df_json[\"Precision\"].append(precision)\n",
    "df_json[\"Recall\"].append(recall)\n",
    "df_json[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc30997e-4d16-48a3-b473-937deff69c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bfa6fbe-4af8-400a-a96d-0f1f53d04e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extremities_Measured_Separately</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.775007</td>\n",
       "      <td>0.729706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.794106</td>\n",
       "      <td>0.805712</td>\n",
       "      <td>0.799867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>0.700097</td>\n",
       "      <td>0.771252</td>\n",
       "      <td>0.733954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.815733</td>\n",
       "      <td>0.820975</td>\n",
       "      <td>0.806114</td>\n",
       "      <td>0.813477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extremities_Measured_Separately            Algorithm  Accuracy  Precision  \\\n",
       "0                              NO  Logistic Regression  0.713808   0.689408   \n",
       "1                             YES  Logistic Regression  0.799024   0.794106   \n",
       "2                              NO        Random Forest  0.721294   0.700097   \n",
       "3                             YES        Random Forest  0.815733   0.820975   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.775007  0.729706  \n",
       "1  0.805712  0.799867  \n",
       "2  0.771252  0.733954  \n",
       "3  0.806114  0.813477  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d90d3a-10f3-463d-9dd5-f515f14ed8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "{} & Extremities\\_Measured\\_Separately &            Algorithm &  Accuracy &  Precision &    Recall &        F1 \\\\\n",
      "\\midrule\n",
      "0 &                              NO &  Logistic Regression &  0.713808 &   0.689408 &  0.775007 &  0.729706 \\\\\n",
      "1 &                             YES &  Logistic Regression &  0.799024 &   0.794106 &  0.805712 &  0.799867 \\\\\n",
      "2 &                              NO &        Random Forest &  0.721294 &   0.700097 &  0.771252 &  0.733954 \\\\\n",
      "3 &                             YES &        Random Forest &  0.815733 &   0.820975 &  0.806114 &  0.813477 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719d366-ae5d-4312-b330-80e5e4a1d59b",
   "metadata": {},
   "source": [
    "### Now add kurtosis and skew to the same thing and measure again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4de1b46-0227-46fa-a6d9-18100c407380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.6901694106418516\n",
      "Recall    : 0.7756771252346474\n",
      "Accuracy  : 0.7146103462103996\n",
      "F1-score  : 0.7304292929292929\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "# X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10, max_iter=1000))]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json2 = {\n",
    "    \"Extremities_Measured_Separately\": [],\n",
    "    \"Algorithm\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1\": []\n",
    "}\n",
    "\n",
    "df_json2[\"Extremities_Measured_Separately\"].append(\"NO\")\n",
    "df_json2[\"Algorithm\"].append(\"Logistic Regression\")\n",
    "df_json2[\"Accuracy\"].append(accuracy)\n",
    "df_json2[\"Precision\"].append(precision)\n",
    "df_json2[\"Recall\"].append(recall)\n",
    "df_json2[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acfea0e5-1975-4be6-94b8-1d17ee189b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.801762114537445\n",
      "Recall    : 0.8053097345132744\n",
      "Accuracy  : 0.8037027135409704\n",
      "F1-score  : 0.8035320088300221\n",
      "['Unnamed: 0', 'baseline.head_shannon_entropy', 'baseline.tail_shannon_entropy', 'baseline.shannon_entropy', 'baseline.montecarlo_pi', 'baseline.chisquare_full', 'baseline.chisquare_begin', 'baseline.chisquare_end', 'baseline.autocorrelation_full', 'baseline.autocorrelation_begin', 'baseline.autocorrelation_end', 'baseline.filesize', 'advanced.kurtosis_full', 'advanced.kurtosis_end', 'advanced.kurtosis_begin', 'advanced.skew_full', 'advanced.skew_begin', 'advanced.skew_end', 'fourier.stat.1byte.autocorr', 'fourier.stat.1byte.mean', 'fourier.stat.1byte.std', 'fourier.value.1byte.0', 'fourier.value.1byte.1', 'fourier.value.1byte.2', 'fourier.value.1byte.3', 'fourier.value.1byte.4', 'fourier.value.1byte.5', 'fourier.value.1byte.6', 'fourier.value.1byte.7', 'fourier.value.1byte.8', 'fourier.value.1byte.9', 'fourier.value.1byte.10', 'fourier.value.1byte.11', 'fourier.value.1byte.12', 'fourier.value.1byte.13', 'fourier.value.1byte.14', 'fourier.value.1byte.15', 'fourier.value.1byte.16', 'fourier.value.1byte.17', 'fourier.value.1byte.18', 'fourier.value.1byte.19', 'fourier.value.1byte.20', 'fourier.value.1byte.21', 'fourier.value.1byte.22', 'fourier.value.1byte.23', 'fourier.value.1byte.24', 'fourier.value.1byte.25', 'fourier.value.1byte.26', 'fourier.value.1byte.27', 'fourier.value.1byte.28', 'fourier.value.1byte.29', 'fourier.value.1byte.30', 'fourier.value.1byte.31', 'fourier.value.1byte.32', 'fourier.value.1byte.33', 'fourier.value.1byte.34', 'fourier.value.1byte.35', 'fourier.value.1byte.36', 'fourier.value.1byte.37', 'fourier.value.1byte.38', 'fourier.value.1byte.39', 'fourier.value.1byte.40', 'fourier.value.1byte.41', 'fourier.value.1byte.42', 'fourier.value.1byte.43', 'fourier.value.1byte.44', 'fourier.value.1byte.45', 'fourier.value.1byte.46', 'fourier.value.1byte.47', 'fourier.value.1byte.48', 'fourier.value.1byte.49', 'fourier.value.1byte.50', 'fourier.value.1byte.51', 'fourier.value.1byte.52', 'fourier.value.1byte.53', 'fourier.value.1byte.54', 'fourier.value.1byte.55', 'fourier.value.1byte.56', 'fourier.value.1byte.57', 'fourier.value.1byte.58', 'fourier.value.1byte.59', 'fourier.value.1byte.60', 'fourier.value.1byte.61', 'fourier.value.1byte.62', 'fourier.value.1byte.63', 'fourier.value.1byte.64', 'fourier.value.1byte.65', 'fourier.value.1byte.66', 'fourier.value.1byte.67', 'fourier.value.1byte.68', 'fourier.value.1byte.69', 'fourier.value.1byte.70', 'fourier.value.1byte.71', 'fourier.value.1byte.72', 'fourier.value.1byte.73', 'fourier.value.1byte.74', 'fourier.value.1byte.75', 'fourier.value.1byte.76', 'fourier.value.1byte.77', 'fourier.value.1byte.78', 'fourier.value.1byte.79', 'fourier.value.1byte.80', 'fourier.value.1byte.81', 'fourier.value.1byte.82', 'fourier.value.1byte.83', 'fourier.value.1byte.84', 'fourier.value.1byte.85', 'fourier.value.1byte.86', 'fourier.value.1byte.87', 'fourier.value.1byte.88', 'fourier.value.1byte.89', 'fourier.value.1byte.90', 'fourier.value.1byte.91', 'fourier.value.1byte.92', 'fourier.value.1byte.93', 'fourier.value.1byte.94', 'fourier.value.1byte.95', 'fourier.value.1byte.96', 'fourier.value.1byte.97', 'fourier.value.1byte.98', 'fourier.value.1byte.99', 'fourier.value.1byte.100', 'fourier.value.1byte.101', 'fourier.value.1byte.102', 'fourier.value.1byte.103', 'fourier.value.1byte.104', 'fourier.value.1byte.105', 'fourier.value.1byte.106', 'fourier.value.1byte.107', 'fourier.value.1byte.108', 'fourier.value.1byte.109', 'fourier.value.1byte.110', 'fourier.value.1byte.111', 'fourier.value.1byte.112', 'fourier.value.1byte.113', 'fourier.value.1byte.114', 'fourier.value.1byte.115', 'fourier.value.1byte.116', 'fourier.value.1byte.117', 'fourier.value.1byte.118', 'fourier.value.1byte.119', 'fourier.value.1byte.120', 'fourier.value.1byte.121', 'fourier.value.1byte.122', 'fourier.value.1byte.123', 'fourier.value.1byte.124', 'fourier.value.1byte.125', 'fourier.value.1byte.126', 'fourier.value.1byte.127', 'fourier.value.1byte.128', 'fourier.value.1byte.129', 'fourier.value.1byte.130', 'fourier.value.1byte.131', 'fourier.value.1byte.132', 'fourier.value.1byte.133', 'fourier.value.1byte.134', 'fourier.value.1byte.135', 'fourier.value.1byte.136', 'fourier.value.1byte.137', 'fourier.value.1byte.138', 'fourier.value.1byte.139', 'fourier.value.1byte.140', 'fourier.value.1byte.141', 'fourier.value.1byte.142', 'fourier.value.1byte.143', 'fourier.value.1byte.144', 'fourier.value.1byte.145', 'fourier.value.1byte.146', 'fourier.value.1byte.147', 'fourier.value.1byte.148', 'fourier.value.1byte.149', 'fourier.value.1byte.150', 'fourier.value.1byte.151', 'fourier.value.1byte.152', 'fourier.value.1byte.153', 'fourier.value.1byte.154', 'fourier.value.1byte.155', 'fourier.value.1byte.156', 'fourier.value.1byte.157', 'fourier.value.1byte.158', 'fourier.value.1byte.159', 'fourier.value.1byte.160', 'fourier.value.1byte.161', 'fourier.value.1byte.162', 'fourier.value.1byte.163', 'fourier.value.1byte.164', 'fourier.value.1byte.165', 'fourier.value.1byte.166', 'fourier.value.1byte.167', 'fourier.value.1byte.168', 'fourier.value.1byte.169', 'fourier.value.1byte.170', 'fourier.value.1byte.171', 'fourier.value.1byte.172', 'fourier.value.1byte.173', 'fourier.value.1byte.174', 'fourier.value.1byte.175', 'fourier.value.1byte.176', 'fourier.value.1byte.177', 'fourier.value.1byte.178', 'fourier.value.1byte.179', 'fourier.value.1byte.180', 'fourier.value.1byte.181', 'fourier.value.1byte.182', 'fourier.value.1byte.183', 'fourier.value.1byte.184', 'fourier.value.1byte.185', 'fourier.value.1byte.186', 'fourier.value.1byte.187', 'fourier.value.1byte.188', 'fourier.value.1byte.189', 'fourier.value.1byte.190', 'fourier.value.1byte.191', 'fourier.value.1byte.192', 'fourier.value.1byte.193', 'fourier.value.1byte.194', 'fourier.value.1byte.195', 'fourier.value.1byte.196', 'fourier.value.1byte.197', 'fourier.value.1byte.198', 'fourier.value.1byte.199', 'fourier.value.1byte.200', 'fourier.value.1byte.201', 'fourier.value.1byte.202', 'fourier.value.1byte.203', 'fourier.value.1byte.204', 'fourier.value.1byte.205', 'fourier.value.1byte.206', 'fourier.value.1byte.207', 'fourier.value.1byte.208', 'fourier.value.1byte.209', 'fourier.value.1byte.210', 'fourier.value.1byte.211', 'fourier.value.1byte.212', 'fourier.value.1byte.213', 'fourier.value.1byte.214', 'fourier.value.1byte.215', 'fourier.value.1byte.216', 'fourier.value.1byte.217', 'fourier.value.1byte.218', 'fourier.value.1byte.219', 'fourier.value.1byte.220', 'fourier.value.1byte.221', 'fourier.value.1byte.222', 'fourier.value.1byte.223', 'fourier.value.1byte.224', 'fourier.value.1byte.225', 'fourier.value.1byte.226', 'fourier.value.1byte.227', 'fourier.value.1byte.228', 'fourier.value.1byte.229', 'fourier.value.1byte.230', 'fourier.value.1byte.231', 'fourier.value.1byte.232', 'fourier.value.1byte.233', 'fourier.value.1byte.234', 'fourier.value.1byte.235', 'fourier.value.1byte.236', 'fourier.value.1byte.237', 'fourier.value.1byte.238', 'fourier.value.1byte.239', 'fourier.value.1byte.240', 'fourier.value.1byte.241', 'fourier.value.1byte.242', 'fourier.value.1byte.243', 'fourier.value.1byte.244', 'fourier.value.1byte.245', 'fourier.value.1byte.246', 'fourier.value.1byte.247', 'fourier.value.1byte.248', 'fourier.value.1byte.249', 'fourier.value.1byte.250', 'fourier.stat.4byte.autocorr', 'fourier.stat.4byte.mean', 'fourier.stat.4byte.std', 'fourier.value.4byte.0', 'fourier.value.4byte.1', 'fourier.value.4byte.2', 'fourier.value.4byte.3', 'fourier.value.4byte.4', 'fourier.value.4byte.5', 'fourier.value.4byte.6', 'fourier.value.4byte.7', 'fourier.value.4byte.8', 'fourier.value.4byte.9', 'fourier.value.4byte.10', 'fourier.value.4byte.11', 'fourier.value.4byte.12', 'fourier.value.4byte.13', 'fourier.value.4byte.14', 'fourier.value.4byte.15', 'fourier.value.4byte.16', 'fourier.value.4byte.17', 'fourier.value.4byte.18', 'fourier.value.4byte.19', 'fourier.value.4byte.20', 'fourier.value.4byte.21', 'fourier.value.4byte.22', 'fourier.value.4byte.23', 'fourier.value.4byte.24', 'fourier.value.4byte.25', 'fourier.value.4byte.26', 'fourier.value.4byte.27', 'fourier.value.4byte.28', 'fourier.value.4byte.29', 'fourier.value.4byte.30', 'fourier.value.4byte.31', 'fourier.value.4byte.32', 'fourier.value.4byte.33', 'fourier.value.4byte.34', 'fourier.value.4byte.35', 'fourier.value.4byte.36', 'fourier.value.4byte.37', 'fourier.value.4byte.38', 'fourier.value.4byte.39', 'fourier.value.4byte.40', 'fourier.value.4byte.41', 'fourier.value.4byte.42', 'fourier.value.4byte.43', 'fourier.value.4byte.44', 'fourier.value.4byte.45', 'fourier.value.4byte.46', 'fourier.value.4byte.47', 'fourier.value.4byte.48', 'fourier.value.4byte.49', 'fourier.value.4byte.50', 'fourier.value.4byte.51', 'fourier.value.4byte.52', 'fourier.value.4byte.53', 'fourier.value.4byte.54', 'fourier.value.4byte.55', 'fourier.value.4byte.56', 'fourier.value.4byte.57', 'fourier.value.4byte.58', 'fourier.value.4byte.59', 'fourier.value.4byte.60', 'fourier.value.4byte.61', 'fourier.value.4byte.62', 'fourier.value.4byte.63', 'fourier.value.4byte.64', 'fourier.value.4byte.65', 'fourier.value.4byte.66', 'fourier.value.4byte.67', 'fourier.value.4byte.68', 'fourier.value.4byte.69', 'fourier.value.4byte.70', 'fourier.value.4byte.71', 'fourier.value.4byte.72', 'fourier.value.4byte.73', 'fourier.value.4byte.74', 'fourier.value.4byte.75', 'fourier.value.4byte.76', 'fourier.value.4byte.77', 'fourier.value.4byte.78', 'fourier.value.4byte.79', 'fourier.value.4byte.80', 'fourier.value.4byte.81', 'fourier.value.4byte.82', 'fourier.value.4byte.83', 'fourier.value.4byte.84', 'fourier.value.4byte.85', 'fourier.value.4byte.86', 'fourier.value.4byte.87', 'fourier.value.4byte.88', 'fourier.value.4byte.89', 'fourier.value.4byte.90', 'fourier.value.4byte.91', 'fourier.value.4byte.92', 'fourier.value.4byte.93', 'fourier.value.4byte.94', 'fourier.value.4byte.95', 'fourier.value.4byte.96', 'fourier.value.4byte.97', 'fourier.value.4byte.98', 'fourier.value.4byte.99', 'fourier.value.4byte.100', 'fourier.value.4byte.101', 'fourier.value.4byte.102', 'fourier.value.4byte.103', 'fourier.value.4byte.104', 'fourier.value.4byte.105', 'fourier.value.4byte.106', 'fourier.value.4byte.107', 'fourier.value.4byte.108', 'fourier.value.4byte.109', 'fourier.value.4byte.110', 'fourier.value.4byte.111', 'fourier.value.4byte.112', 'fourier.value.4byte.113', 'fourier.value.4byte.114', 'fourier.value.4byte.115', 'fourier.value.4byte.116', 'fourier.value.4byte.117', 'fourier.value.4byte.118', 'fourier.value.4byte.119', 'fourier.value.4byte.120', 'fourier.value.4byte.121', 'fourier.value.4byte.122', 'fourier.value.4byte.123', 'fourier.value.4byte.124', 'fourier.value.4byte.125', 'fourier.value.4byte.126', 'fourier.value.4byte.127', 'fourier.value.4byte.128', 'fourier.value.4byte.129', 'fourier.value.4byte.130', 'fourier.value.4byte.131', 'fourier.value.4byte.132', 'fourier.value.4byte.133', 'fourier.value.4byte.134', 'fourier.value.4byte.135', 'fourier.value.4byte.136', 'fourier.value.4byte.137', 'fourier.value.4byte.138', 'fourier.value.4byte.139', 'fourier.value.4byte.140', 'fourier.value.4byte.141', 'fourier.value.4byte.142', 'fourier.value.4byte.143', 'fourier.value.4byte.144', 'fourier.value.4byte.145', 'fourier.value.4byte.146', 'fourier.value.4byte.147', 'fourier.value.4byte.148', 'fourier.value.4byte.149', 'fourier.value.4byte.150', 'fourier.value.4byte.151', 'fourier.value.4byte.152', 'fourier.value.4byte.153', 'fourier.value.4byte.154', 'fourier.value.4byte.155', 'fourier.value.4byte.156', 'fourier.value.4byte.157', 'fourier.value.4byte.158', 'fourier.value.4byte.159', 'fourier.value.4byte.160', 'fourier.value.4byte.161', 'fourier.value.4byte.162', 'fourier.value.4byte.163', 'fourier.value.4byte.164', 'fourier.value.4byte.165', 'fourier.value.4byte.166', 'fourier.value.4byte.167', 'fourier.value.4byte.168', 'fourier.value.4byte.169', 'fourier.value.4byte.170', 'fourier.value.4byte.171', 'fourier.value.4byte.172', 'fourier.value.4byte.173', 'fourier.value.4byte.174', 'fourier.value.4byte.175', 'fourier.value.4byte.176', 'fourier.value.4byte.177', 'fourier.value.4byte.178', 'fourier.value.4byte.179', 'fourier.value.4byte.180', 'fourier.value.4byte.181', 'fourier.value.4byte.182', 'fourier.value.4byte.183', 'fourier.value.4byte.184', 'fourier.value.4byte.185', 'fourier.value.4byte.186', 'fourier.value.4byte.187', 'fourier.value.4byte.188', 'fourier.value.4byte.189', 'fourier.value.4byte.190', 'fourier.value.4byte.191', 'fourier.value.4byte.192', 'fourier.value.4byte.193', 'fourier.value.4byte.194', 'fourier.value.4byte.195', 'fourier.value.4byte.196', 'fourier.value.4byte.197', 'fourier.value.4byte.198', 'fourier.value.4byte.199', 'fourier.value.4byte.200', 'fourier.value.4byte.201', 'fourier.value.4byte.202', 'fourier.value.4byte.203', 'fourier.value.4byte.204', 'fourier.value.4byte.205', 'fourier.value.4byte.206', 'fourier.value.4byte.207', 'fourier.value.4byte.208', 'fourier.value.4byte.209', 'fourier.value.4byte.210', 'fourier.value.4byte.211', 'fourier.value.4byte.212', 'fourier.value.4byte.213', 'fourier.value.4byte.214', 'fourier.value.4byte.215', 'fourier.value.4byte.216', 'fourier.value.4byte.217', 'fourier.value.4byte.218', 'fourier.value.4byte.219', 'fourier.value.4byte.220', 'fourier.value.4byte.221', 'fourier.value.4byte.222', 'fourier.value.4byte.223', 'fourier.value.4byte.224', 'fourier.value.4byte.225', 'fourier.value.4byte.226', 'fourier.value.4byte.227', 'fourier.value.4byte.228', 'fourier.value.4byte.229', 'fourier.value.4byte.230', 'fourier.value.4byte.231', 'fourier.value.4byte.232', 'fourier.value.4byte.233', 'fourier.value.4byte.234', 'fourier.value.4byte.235', 'fourier.value.4byte.236', 'fourier.value.4byte.237', 'fourier.value.4byte.238', 'fourier.value.4byte.239', 'fourier.value.4byte.240', 'fourier.value.4byte.241', 'fourier.value.4byte.242', 'fourier.value.4byte.243', 'fourier.value.4byte.244', 'fourier.value.4byte.245', 'fourier.value.4byte.246', 'fourier.value.4byte.247', 'fourier.value.4byte.248', 'fourier.value.4byte.249', 'fourier.value.4byte.250']\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "# X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "# X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "# X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10, max_iter=1000))]\n",
    "#estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "\n",
    "df_json2[\"Extremities_Measured_Separately\"].append(\"YES\")\n",
    "df_json2[\"Algorithm\"].append(\"Logistic Regression\")\n",
    "df_json2[\"Accuracy\"].append(accuracy)\n",
    "df_json2[\"Precision\"].append(precision)\n",
    "df_json2[\"Recall\"].append(recall)\n",
    "df_json2[\"F1\"].append(f1)\n",
    "\n",
    "print([c for c in X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6851708-b4a8-4531-868a-1714f5efc8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7005360623781677\n",
      "Recall    : 0.7709841780638241\n",
      "Accuracy  : 0.721561288597781\n",
      "F1-score  : 0.7340737903740585\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "# X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "#estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10, max_iter=1000))]\n",
    "estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json2[\"Extremities_Measured_Separately\"].append(\"NO\")\n",
    "df_json2[\"Algorithm\"].append(\"Random Forest\")\n",
    "df_json2[\"Accuracy\"].append(accuracy)\n",
    "df_json2[\"Precision\"].append(precision)\n",
    "df_json2[\"Recall\"].append(recall)\n",
    "df_json2[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30bdc618-d6a5-4d9e-8d58-70666b6d66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.8182314410480349\n",
      "Recall    : 0.8039688924644677\n",
      "Accuracy  : 0.8132602593236198\n",
      "F1-score  : 0.8110374678750168\n"
     ]
    }
   ],
   "source": [
    "#columns_to_consider = [c for c in master_df.columns]\n",
    "#columns_to_consider = [c for c in master_df.columns if c.startswith(\"baseline\")]\n",
    "#columns_to_consider.append('is_encrypted')\n",
    "columns_to_consider = [c for c in master_df.columns if c != 'extended.extension']\n",
    "\n",
    "\n",
    "interesting_df = master_df[columns_to_consider]\n",
    "\n",
    "X = interesting_df[[c for c in interesting_df.columns if c.startswith('baseline')]]\n",
    "X = interesting_df[[c for c in interesting_df.columns if c != 'is_encrypted']]\n",
    "X = X[[c for c in X.columns if c != 'is_encrypted']]\n",
    "\n",
    "# get rid of tail and head metrics\n",
    "# X = X[[c for c in X.columns if \"begin\" not in c and \"head\" not in c]]\n",
    "# X = X[[c for c in X.columns if \"tail\" not in c and \"end\" not in c]]\n",
    "\n",
    "# X = X[[c for c in X.columns if \"kurtosis\" not in c and \"skew\" not in c]]\n",
    "\n",
    "y = interesting_df['is_encrypted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "#estimators = [('std,', MinMaxScaler()), ('LogisticRegressor', LogisticRegression(n_jobs=10, max_iter=1000))]\n",
    "estimators = [('std,', MinMaxScaler()), ('RFC', rfc)]\n",
    "pipeline = Pipeline(estimators)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision : {precision}\")\n",
    "print(f\"Recall    : {recall}\")\n",
    "print(f\"Accuracy  : {accuracy}\")\n",
    "print(f\"F1-score  : {f1}\")\n",
    "\n",
    "df_json2[\"Extremities_Measured_Separately\"].append(\"YES\")\n",
    "df_json2[\"Algorithm\"].append(\"Random Forest\")\n",
    "df_json2[\"Accuracy\"].append(accuracy)\n",
    "df_json2[\"Precision\"].append(precision)\n",
    "df_json2[\"Recall\"].append(recall)\n",
    "df_json2[\"F1\"].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9182b8b8-1bf9-414c-a074-763bf88c4fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extremities_Measured_Separately</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.690169</td>\n",
       "      <td>0.775677</td>\n",
       "      <td>0.730429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.803703</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.803532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721561</td>\n",
       "      <td>0.700536</td>\n",
       "      <td>0.770984</td>\n",
       "      <td>0.734074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.813260</td>\n",
       "      <td>0.818231</td>\n",
       "      <td>0.803969</td>\n",
       "      <td>0.811037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extremities_Measured_Separately            Algorithm  Accuracy  Precision  \\\n",
       "0                              NO  Logistic Regression  0.714610   0.690169   \n",
       "1                             YES  Logistic Regression  0.803703   0.801762   \n",
       "2                              NO        Random Forest  0.721561   0.700536   \n",
       "3                             YES        Random Forest  0.813260   0.818231   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.775677  0.730429  \n",
       "1  0.805310  0.803532  \n",
       "2  0.770984  0.734074  \n",
       "3  0.803969  0.811037  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df_json2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7eee1a1-ebea-4055-adea-da418c74122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "{} & Extremities\\_Measured\\_Separately &            Algorithm &  Accuracy &  Precision &    Recall &        F1 \\\\\n",
      "\\midrule\n",
      "0 &                              NO &  Logistic Regression &  0.714610 &   0.690169 &  0.775677 &  0.730429 \\\\\n",
      "1 &                             YES &  Logistic Regression &  0.803703 &   0.801762 &  0.805310 &  0.803532 \\\\\n",
      "2 &                              NO &        Random Forest &  0.721561 &   0.700536 &  0.770984 &  0.734074 \\\\\n",
      "3 &                             YES &        Random Forest &  0.813260 &   0.818231 &  0.803969 &  0.811037 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df2.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38895bac-986c-4fd6-b915-59ab96bc47fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extremities_Measured_Separately</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.775007</td>\n",
       "      <td>0.729706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YES</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.794106</td>\n",
       "      <td>0.805712</td>\n",
       "      <td>0.799867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>0.700097</td>\n",
       "      <td>0.771252</td>\n",
       "      <td>0.733954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YES</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.815733</td>\n",
       "      <td>0.820975</td>\n",
       "      <td>0.806114</td>\n",
       "      <td>0.813477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Extremities_Measured_Separately            Algorithm  Accuracy  Precision  \\\n",
       "0                              NO  Logistic Regression  0.713808   0.689408   \n",
       "1                             YES  Logistic Regression  0.799024   0.794106   \n",
       "2                              NO        Random Forest  0.721294   0.700097   \n",
       "3                             YES        Random Forest  0.815733   0.820975   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.775007  0.729706  \n",
       "1  0.805712  0.799867  \n",
       "2  0.771252  0.733954  \n",
       "3  0.806114  0.813477  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba09e035-75fd-4c38-a57c-9a8abda7b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "{} & Extremities\\_Measured\\_Separately &            Algorithm &  Accuracy &  Precision &    Recall &        F1 \\\\\n",
      "\\midrule\n",
      "0 &                              NO &  Logistic Regression &  0.713808 &   0.689408 &  0.775007 &  0.729706 \\\\\n",
      "1 &                             YES &  Logistic Regression &  0.799024 &   0.794106 &  0.805712 &  0.799867 \\\\\n",
      "2 &                              NO &        Random Forest &  0.721294 &   0.700097 &  0.771252 &  0.733954 \\\\\n",
      "3 &                             YES &        Random Forest &  0.815733 &   0.820975 &  0.806114 &  0.813477 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0af2f040-403b-4162-8129-ed3657fa0ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.763284</td>\n",
       "      <td>0.052412</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.719824</td>\n",
       "      <td>0.762632</td>\n",
       "      <td>0.806092</td>\n",
       "      <td>0.813260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.752675</td>\n",
       "      <td>0.066665</td>\n",
       "      <td>0.690169</td>\n",
       "      <td>0.697944</td>\n",
       "      <td>0.751149</td>\n",
       "      <td>0.805879</td>\n",
       "      <td>0.818231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.770984</td>\n",
       "      <td>0.774504</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.805310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.769768</td>\n",
       "      <td>0.043454</td>\n",
       "      <td>0.730429</td>\n",
       "      <td>0.733163</td>\n",
       "      <td>0.768803</td>\n",
       "      <td>0.805408</td>\n",
       "      <td>0.811037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "Accuracy     4.0  0.763284  0.052412  0.714610  0.719824  0.762632  0.806092   \n",
       "Precision    4.0  0.752675  0.066665  0.690169  0.697944  0.751149  0.805879   \n",
       "Recall       4.0  0.788985  0.018186  0.770984  0.774504  0.789823  0.804304   \n",
       "F1           4.0  0.769768  0.043454  0.730429  0.733163  0.768803  0.805408   \n",
       "\n",
       "                max  \n",
       "Accuracy   0.813260  \n",
       "Precision  0.818231  \n",
       "Recall     0.805310  \n",
       "F1         0.811037  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1139a21d-4530-4783-a0a4-f14abae5e8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.762465</td>\n",
       "      <td>0.052398</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.719423</td>\n",
       "      <td>0.760159</td>\n",
       "      <td>0.803201</td>\n",
       "      <td>0.815733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.066179</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.697425</td>\n",
       "      <td>0.747102</td>\n",
       "      <td>0.800823</td>\n",
       "      <td>0.820975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.789521</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.771252</td>\n",
       "      <td>0.774068</td>\n",
       "      <td>0.790359</td>\n",
       "      <td>0.805813</td>\n",
       "      <td>0.806114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.769251</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.729706</td>\n",
       "      <td>0.732892</td>\n",
       "      <td>0.766911</td>\n",
       "      <td>0.803269</td>\n",
       "      <td>0.813477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "Accuracy     4.0  0.762465  0.052398  0.713808  0.719423  0.760159  0.803201   \n",
       "Precision    4.0  0.751147  0.066179  0.689408  0.697425  0.747102  0.800823   \n",
       "Recall       4.0  0.789521  0.018990  0.771252  0.774068  0.790359  0.805813   \n",
       "F1           4.0  0.769251  0.043600  0.729706  0.732892  0.766911  0.803269   \n",
       "\n",
       "                max  \n",
       "Accuracy   0.815733  \n",
       "Precision  0.820975  \n",
       "Recall     0.806114  \n",
       "F1         0.813477  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "873bcd9a-e34a-4637-a477-3acf5747992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_18157/3964534304.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df3 = pd.DataFrame({\"With Skew and Kurtosis (averages)\": df2.mean(), \"Without Skew and Kurtosis (averages)\": df.mean()}).T\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({\"With Skew and Kurtosis (averages)\": df2.mean(), \"Without Skew and Kurtosis (averages)\": df.mean()}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5adeba59-1fcf-48b1-bc63-b9ff858515fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>With Skew and Kurtosis (averages)</th>\n",
       "      <td>0.763284</td>\n",
       "      <td>0.752675</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>0.769768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Without Skew and Kurtosis (averages)</th>\n",
       "      <td>0.762465</td>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.789521</td>\n",
       "      <td>0.769251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Accuracy  Precision    Recall        F1\n",
       "With Skew and Kurtosis (averages)     0.763284   0.752675  0.788985  0.769768\n",
       "Without Skew and Kurtosis (averages)  0.762465   0.751147  0.789521  0.769251"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c0317b-e871-469e-a729-6f0cdeefea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  Accuracy &  Precision &    Recall &        F1 \\\\\n",
      "\\midrule\n",
      "With Skew and Kurtosis (averages)    &  0.763284 &   0.752675 &  0.788985 &  0.769768 \\\\\n",
      "Without Skew and Kurtosis (averages) &  0.762465 &   0.751147 &  0.789521 &  0.769251 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df3.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d08b5a3f-83af-4bd3-88fb-39b84177c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"extremity-compared-without-kurtosis.csv\")\n",
    "df2.to_csv(\"extremity-compared-with-kurtosis.csv\")\n",
    "df3.to_csv(\"with-and-without-kurtosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2f91b8d-cf02-4b36-9e5c-af959d7681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Kurtosis and Skew Used\"] = 0\n",
    "df2[\"Kurtosis and Skew Used\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c882cffe-aad1-4d07-be8c-0fe9a43663e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51f23a33-44be-426f-a49f-7ce5ec6ecaab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Extremities_Measured_Separately'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Extremities_Measured_Separately'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_18157/2078537997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Extremities Measured Separately\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Extremities_Measured_Separately\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extremities_Measured_Separately\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Extremities_Measured_Separately'"
     ]
    }
   ],
   "source": [
    "df_final[\"Extremities Measured Separately\"] = df_final[\"Extremities_Measured_Separately\"]\n",
    "df_final = df_final.drop(\"Extremities_Measured_Separately\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80f27dcb-b0b8-4205-b6d6-afad3d956292",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z1/hfz3q2b52bx3hb8nh0z1q89c0000gp/T/ipykernel_18157/3688066548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5797\u001b[0m                     )\n\u001b[1;32m   5798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5799\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5801\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4414\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4416\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "df_final = df_final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e17fbea3-01b8-472c-b797-f3f3dbc6e90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "320ee675-77ca-4ca0-9bd3-10c33820555e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrrrrrl}\\n\\\\toprule\\n{} &            Algorithm &  Accuracy &  Precision &    Recall &        F1 &  Kurtosis and Skew Used & Extremities Measured Separately \\\\\\\\\\n\\\\midrule\\n0 &  Logistic Regression &  0.713808 &   0.689408 &  0.775007 &  0.729706 &                       0 &                              NO \\\\\\\\\\n1 &  Logistic Regression &  0.799024 &   0.794106 &  0.805712 &  0.799867 &                       0 &                             YES \\\\\\\\\\n2 &        Random Forest &  0.721294 &   0.700097 &  0.771252 &  0.733954 &                       0 &                              NO \\\\\\\\\\n3 &        Random Forest &  0.815733 &   0.820975 &  0.806114 &  0.813477 &                       0 &                             YES \\\\\\\\\\n0 &  Logistic Regression &  0.714610 &   0.690169 &  0.775677 &  0.730429 &                       1 &                              NO \\\\\\\\\\n1 &  Logistic Regression &  0.803703 &   0.801762 &  0.805310 &  0.803532 &                       1 &                             YES \\\\\\\\\\n2 &        Random Forest &  0.721561 &   0.700536 &  0.770984 &  0.734074 &                       1 &                              NO \\\\\\\\\\n3 &        Random Forest &  0.813260 &   0.818231 &  0.803969 &  0.811037 &                       1 &                             YES \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6df05040-e3c4-4164-b720-eed1fc6d848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ad015d6-f4ed-4a3a-a51e-76641db4eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(\"level_0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd56a703-850c-4eda-9c4d-10589297c426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kurtosis and Skew Used</th>\n",
       "      <th>Extremities Measured Separately</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.689408</td>\n",
       "      <td>0.775007</td>\n",
       "      <td>0.729706</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.794106</td>\n",
       "      <td>0.805712</td>\n",
       "      <td>0.799867</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>0.700097</td>\n",
       "      <td>0.771252</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.815733</td>\n",
       "      <td>0.820975</td>\n",
       "      <td>0.806114</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.690169</td>\n",
       "      <td>0.775677</td>\n",
       "      <td>0.730429</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.803703</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.803532</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.721561</td>\n",
       "      <td>0.700536</td>\n",
       "      <td>0.770984</td>\n",
       "      <td>0.734074</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.813260</td>\n",
       "      <td>0.818231</td>\n",
       "      <td>0.803969</td>\n",
       "      <td>0.811037</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.713808   0.689408  0.775007  0.729706   \n",
       "1  Logistic Regression  0.799024   0.794106  0.805712  0.799867   \n",
       "2        Random Forest  0.721294   0.700097  0.771252  0.733954   \n",
       "3        Random Forest  0.815733   0.820975  0.806114  0.813477   \n",
       "4  Logistic Regression  0.714610   0.690169  0.775677  0.730429   \n",
       "5  Logistic Regression  0.803703   0.801762  0.805310  0.803532   \n",
       "6        Random Forest  0.721561   0.700536  0.770984  0.734074   \n",
       "7        Random Forest  0.813260   0.818231  0.803969  0.811037   \n",
       "\n",
       "   Kurtosis and Skew Used Extremities Measured Separately  \n",
       "0                       0                              NO  \n",
       "1                       0                             YES  \n",
       "2                       0                              NO  \n",
       "3                       0                             YES  \n",
       "4                       1                              NO  \n",
       "5                       1                             YES  \n",
       "6                       1                              NO  \n",
       "7                       1                             YES  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "341ec1fd-5029-436c-8703-45e204af9124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrl}\n",
      "\\toprule\n",
      "{} &            Algorithm &  Accuracy &  Precision &    Recall &        F1 &  Kurtosis and Skew Used & Extremities Measured Separately \\\\\n",
      "\\midrule\n",
      "0 &  Logistic Regression &  0.713808 &   0.689408 &  0.775007 &  0.729706 &                       0 &                              NO \\\\\n",
      "1 &  Logistic Regression &  0.799024 &   0.794106 &  0.805712 &  0.799867 &                       0 &                             YES \\\\\n",
      "2 &        Random Forest &  0.721294 &   0.700097 &  0.771252 &  0.733954 &                       0 &                              NO \\\\\n",
      "3 &        Random Forest &  0.815733 &   0.820975 &  0.806114 &  0.813477 &                       0 &                             YES \\\\\n",
      "4 &  Logistic Regression &  0.714610 &   0.690169 &  0.775677 &  0.730429 &                       1 &                              NO \\\\\n",
      "5 &  Logistic Regression &  0.803703 &   0.801762 &  0.805310 &  0.803532 &                       1 &                             YES \\\\\n",
      "6 &        Random Forest &  0.721561 &   0.700536 &  0.770984 &  0.734074 &                       1 &                              NO \\\\\n",
      "7 &        Random Forest &  0.813260 &   0.818231 &  0.803969 &  0.811037 &                       1 &                             YES \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_final.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cabea31-355a-4abc-bf51-ca6a85f4f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"extremity-kurtosis-skew-measured.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b0e15-dc3a-4df5-acd9-74473ffcc358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
